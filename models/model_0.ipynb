{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f8f251e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = \"cuda\"\n",
    "torch.device(device=device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9dfc4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.002\n",
    "HIDDEN_UNITS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "866bb657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[[0.45497363805770874,\n",
       "    0.40181559324264526,\n",
       "    -0.10442516207695007,\n",
       "    0.9964860677719116],\n",
       "   [0.46596378087997437,\n",
       "    0.3687018156051636,\n",
       "    -0.14153742790222168,\n",
       "    0.9968416690826416],\n",
       "   [0.47041770815849304,\n",
       "    0.36795997619628906,\n",
       "    -0.141709566116333,\n",
       "    0.9973503351211548],\n",
       "   [0.4751827120780945,\n",
       "    0.3672834634780884,\n",
       "    -0.14179515838623047,\n",
       "    0.9976590871810913],\n",
       "   [0.4611609876155853,\n",
       "    0.3686749339103699,\n",
       "    -0.0905613824725151,\n",
       "    0.9964673519134521],\n",
       "   [0.46208521723747253,\n",
       "    0.3676823377609253,\n",
       "    -0.09063052386045456,\n",
       "    0.9964346885681152],\n",
       "   [0.46336010098457336,\n",
       "    0.36653953790664673,\n",
       "    -0.09079504758119583,\n",
       "    0.9968423843383789],\n",
       "   [0.50380539894104,\n",
       "    0.3792932629585266,\n",
       "    -0.2224762737751007,\n",
       "    0.9974061846733093],\n",
       "   [0.4925134778022766,\n",
       "    0.37584102153778076,\n",
       "    0.0051500811241567135,\n",
       "    0.9974742531776428],\n",
       "   [0.4672686755657196,\n",
       "    0.43053245544433594,\n",
       "    -0.12731407582759857,\n",
       "    0.9970880150794983],\n",
       "   [0.461368590593338,\n",
       "    0.43222153186798096,\n",
       "    -0.06125153601169586,\n",
       "    0.993300199508667],\n",
       "   [0.5282040238380432,\n",
       "    0.5542018413543701,\n",
       "    -0.3417438268661499,\n",
       "    0.9962043166160583],\n",
       "   [0.517397403717041,\n",
       "    0.5377851724624634,\n",
       "    0.16241537034511566,\n",
       "    0.9910175800323486],\n",
       "   [0.4036928713321686,\n",
       "    0.7270089983940125,\n",
       "    -0.3720029592514038,\n",
       "    0.9829034209251404],\n",
       "   [0.49901068210601807,\n",
       "    0.7078642249107361,\n",
       "    0.30156102776527405,\n",
       "    0.05807540938258171],\n",
       "   [0.24956157803535461,\n",
       "    0.7239622473716736,\n",
       "    -0.2466471940279007,\n",
       "    0.9607005715370178],\n",
       "   [0.4708140790462494,\n",
       "    0.820203423500061,\n",
       "    0.2937680184841156,\n",
       "    0.061860132962465286],\n",
       "   [0.205746591091156,\n",
       "    0.7511589527130127,\n",
       "    -0.2833341956138611,\n",
       "    0.947521448135376],\n",
       "   [0.47134944796562195,\n",
       "    0.8505309820175171,\n",
       "    0.30123665928840637,\n",
       "    0.07873117178678513],\n",
       "   [0.19761571288108826,\n",
       "    0.7324362397193909,\n",
       "    -0.2591188848018646,\n",
       "    0.9492519497871399],\n",
       "   [0.4694514274597168,\n",
       "    0.8382806777954102,\n",
       "    0.2613980770111084,\n",
       "    0.08160863071680069],\n",
       "   [0.2106485366821289,\n",
       "    0.728890061378479,\n",
       "    -0.2318090796470642,\n",
       "    0.9271935820579529],\n",
       "   [0.4716237485408783,\n",
       "    0.8285304307937622,\n",
       "    0.276228129863739,\n",
       "    0.08687566965818405],\n",
       "   [0.5458189845085144,\n",
       "    0.9663140177726746,\n",
       "    -0.13774797320365906,\n",
       "    0.9569915533065796],\n",
       "   [0.5234227180480957,\n",
       "    0.9452158212661743,\n",
       "    0.1380530297756195,\n",
       "    0.9416497945785522],\n",
       "   [0.3861454129219055,\n",
       "    0.9567484259605408,\n",
       "    -0.169699564576149,\n",
       "    0.5225474834442139],\n",
       "   [0.3647574484348297,\n",
       "    1.0055861473083496,\n",
       "    0.19781222939491272,\n",
       "    0.32368049025535583],\n",
       "   [0.38912585377693176,\n",
       "    1.2169058322906494,\n",
       "    0.0631200522184372,\n",
       "    0.22854064404964447],\n",
       "   [0.4274769723415375,\n",
       "    1.172460913658142,\n",
       "    0.31556183099746704,\n",
       "    0.08525165915489197],\n",
       "   [0.4086255729198456,\n",
       "    1.2516629695892334,\n",
       "    0.08864039182662964,\n",
       "    0.2902369797229767],\n",
       "   [0.44896045327186584,\n",
       "    1.1922600269317627,\n",
       "    0.3293534815311432,\n",
       "    0.20396873354911804],\n",
       "   [0.32387882471084595,\n",
       "    1.2676098346710205,\n",
       "    0.10328394919633865,\n",
       "    0.19046135246753693],\n",
       "   [0.3919506371021271,\n",
       "    1.241142749786377,\n",
       "    0.3570573925971985,\n",
       "    0.1053805947303772]],\n",
       "  1],\n",
       " 33)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = None\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data[0], len(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "db2f7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = []\n",
    "labels = []\n",
    "for pose in data:\n",
    "  landmarks.append(pose[0])\n",
    "  labels.append(pose[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "88b619e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4550,  0.4018, -0.1044,  0.9965],\n",
       "         [ 0.4660,  0.3687, -0.1415,  0.9968],\n",
       "         [ 0.4704,  0.3680, -0.1417,  0.9974],\n",
       "         [ 0.4752,  0.3673, -0.1418,  0.9977],\n",
       "         [ 0.4612,  0.3687, -0.0906,  0.9965],\n",
       "         [ 0.4621,  0.3677, -0.0906,  0.9964],\n",
       "         [ 0.4634,  0.3665, -0.0908,  0.9968],\n",
       "         [ 0.5038,  0.3793, -0.2225,  0.9974],\n",
       "         [ 0.4925,  0.3758,  0.0052,  0.9975],\n",
       "         [ 0.4673,  0.4305, -0.1273,  0.9971],\n",
       "         [ 0.4614,  0.4322, -0.0613,  0.9933],\n",
       "         [ 0.5282,  0.5542, -0.3417,  0.9962],\n",
       "         [ 0.5174,  0.5378,  0.1624,  0.9910],\n",
       "         [ 0.4037,  0.7270, -0.3720,  0.9829],\n",
       "         [ 0.4990,  0.7079,  0.3016,  0.0581],\n",
       "         [ 0.2496,  0.7240, -0.2466,  0.9607],\n",
       "         [ 0.4708,  0.8202,  0.2938,  0.0619],\n",
       "         [ 0.2057,  0.7512, -0.2833,  0.9475],\n",
       "         [ 0.4713,  0.8505,  0.3012,  0.0787],\n",
       "         [ 0.1976,  0.7324, -0.2591,  0.9493],\n",
       "         [ 0.4695,  0.8383,  0.2614,  0.0816],\n",
       "         [ 0.2106,  0.7289, -0.2318,  0.9272],\n",
       "         [ 0.4716,  0.8285,  0.2762,  0.0869],\n",
       "         [ 0.5458,  0.9663, -0.1377,  0.9570],\n",
       "         [ 0.5234,  0.9452,  0.1381,  0.9416],\n",
       "         [ 0.3861,  0.9567, -0.1697,  0.5225],\n",
       "         [ 0.3648,  1.0056,  0.1978,  0.3237],\n",
       "         [ 0.3891,  1.2169,  0.0631,  0.2285],\n",
       "         [ 0.4275,  1.1725,  0.3156,  0.0853],\n",
       "         [ 0.4086,  1.2517,  0.0886,  0.2902],\n",
       "         [ 0.4490,  1.1923,  0.3294,  0.2040],\n",
       "         [ 0.3239,  1.2676,  0.1033,  0.1905],\n",
       "         [ 0.3920,  1.2411,  0.3571,  0.1054]], device='cuda:0'),\n",
       " tensor(1, device='cuda:0'))"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks = torch.tensor(landmarks, dtype=torch.float).to(device=device)\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device=device)\n",
    "landmarks[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ee0f8e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0250e-01,  1.6727e-01, -6.8490e-01,  9.9973e-01],\n",
       "        [ 5.9902e-01,  1.0687e-01, -6.1972e-01,  9.9929e-01],\n",
       "        [ 6.0531e-01,  1.0729e-01, -6.1963e-01,  9.9938e-01],\n",
       "        [ 6.1074e-01,  1.0761e-01, -6.1963e-01,  9.9942e-01],\n",
       "        [ 5.6670e-01,  1.0544e-01, -6.9195e-01,  9.9935e-01],\n",
       "        [ 5.4912e-01,  1.0594e-01, -6.9207e-01,  9.9939e-01],\n",
       "        [ 5.2903e-01,  1.0697e-01, -6.9247e-01,  9.9931e-01],\n",
       "        [ 5.6801e-01,  1.4479e-01, -3.4747e-01,  9.9952e-01],\n",
       "        [ 4.6859e-01,  1.4294e-01, -6.5422e-01,  9.9969e-01],\n",
       "        [ 6.0467e-01,  2.5077e-01, -5.8702e-01,  9.9986e-01],\n",
       "        [ 5.6339e-01,  2.5049e-01, -6.7493e-01,  9.9990e-01],\n",
       "        [ 6.4910e-01,  6.2519e-01, -1.5255e-01,  9.9898e-01],\n",
       "        [ 2.6221e-01,  5.9242e-01, -7.2429e-01,  9.9866e-01],\n",
       "        [ 7.1213e-01,  1.0620e+00, -2.3510e-02,  3.8240e-01],\n",
       "        [ 2.0682e-01,  1.1385e+00, -6.7991e-01,  5.1860e-01],\n",
       "        [ 7.1690e-01,  1.4073e+00, -1.7730e-01,  5.0210e-02],\n",
       "        [ 2.9788e-01,  1.4992e+00, -7.7389e-01,  1.4333e-01],\n",
       "        [ 7.3795e-01,  1.5097e+00, -2.4489e-01,  5.1066e-02],\n",
       "        [ 2.9935e-01,  1.6148e+00, -8.6184e-01,  1.5815e-01],\n",
       "        [ 6.9683e-01,  1.5095e+00, -2.8562e-01,  7.7423e-02],\n",
       "        [ 3.4145e-01,  1.5998e+00, -9.2157e-01,  2.0405e-01],\n",
       "        [ 6.8340e-01,  1.4767e+00, -2.1059e-01,  9.3420e-02],\n",
       "        [ 3.4606e-01,  1.5553e+00, -8.0398e-01,  2.0463e-01],\n",
       "        [ 5.5426e-01,  1.3365e+00,  1.2360e-01,  5.7146e-03],\n",
       "        [ 3.1970e-01,  1.3478e+00, -1.1996e-01,  4.8535e-03],\n",
       "        [ 5.5504e-01,  1.9218e+00,  3.1134e-01,  4.2536e-04],\n",
       "        [ 3.3850e-01,  1.9645e+00,  1.0694e-01,  6.9559e-04],\n",
       "        [ 5.4551e-01,  2.4411e+00,  1.0905e+00,  2.0291e-05],\n",
       "        [ 3.2776e-01,  2.4466e+00,  7.2243e-01,  1.0989e-05],\n",
       "        [ 5.3574e-01,  2.5431e+00,  1.1410e+00,  1.6009e-05],\n",
       "        [ 3.0280e-01,  2.5379e+00,  7.6563e-01,  1.5368e-05],\n",
       "        [ 5.8312e-01,  2.5987e+00,  7.5992e-01,  1.3667e-04],\n",
       "        [ 4.2895e-01,  2.6112e+00,  2.8196e-01,  5.5959e-05]], device='cuda:0')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(landmarks,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=42)\n",
    "Y_train = Y_train.to(device)\n",
    "Y_test = Y_test.to(device)\n",
    "\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a3e99037",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.view(X_test.size(0), -1)\n",
    "X_train = X_train.view(X_train.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2dd070db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=132, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0 = nn.Sequential(\n",
    "  nn.Linear(132, HIDDEN_UNITS),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(HIDDEN_UNITS, HIDDEN_UNITS),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(HIDDEN_UNITS, 2)\n",
    ").to(device=device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d7874400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_preds):\n",
    "  correct = torch.eq(y_true, y_preds).sum().item()\n",
    "  return (correct / len(y_preds)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "41e68b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(device=device)\n",
    "optimizer = torch.optim.SGD(model_0.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "ee32eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_labels(y_logits):\n",
    "  y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "  y_preds = torch.argmax(y_pred_probs, dim=1)\n",
    "  return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "80cbf7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6.0250e-01,  1.6727e-01, -6.8490e-01,  9.9973e-01,  5.9902e-01,\n",
       "           1.0687e-01, -6.1972e-01,  9.9929e-01,  6.0531e-01,  1.0729e-01,\n",
       "          -6.1963e-01,  9.9938e-01,  6.1074e-01,  1.0761e-01, -6.1963e-01,\n",
       "           9.9942e-01,  5.6670e-01,  1.0544e-01, -6.9195e-01,  9.9935e-01,\n",
       "           5.4912e-01,  1.0594e-01, -6.9207e-01,  9.9939e-01,  5.2903e-01,\n",
       "           1.0697e-01, -6.9247e-01,  9.9931e-01,  5.6801e-01,  1.4479e-01,\n",
       "          -3.4747e-01,  9.9952e-01,  4.6859e-01,  1.4294e-01, -6.5422e-01,\n",
       "           9.9969e-01,  6.0467e-01,  2.5077e-01, -5.8702e-01,  9.9986e-01,\n",
       "           5.6339e-01,  2.5049e-01, -6.7493e-01,  9.9990e-01,  6.4910e-01,\n",
       "           6.2519e-01, -1.5255e-01,  9.9898e-01,  2.6221e-01,  5.9242e-01,\n",
       "          -7.2429e-01,  9.9866e-01,  7.1213e-01,  1.0620e+00, -2.3510e-02,\n",
       "           3.8240e-01,  2.0682e-01,  1.1385e+00, -6.7991e-01,  5.1860e-01,\n",
       "           7.1690e-01,  1.4073e+00, -1.7730e-01,  5.0210e-02,  2.9788e-01,\n",
       "           1.4992e+00, -7.7389e-01,  1.4333e-01,  7.3795e-01,  1.5097e+00,\n",
       "          -2.4489e-01,  5.1066e-02,  2.9935e-01,  1.6148e+00, -8.6184e-01,\n",
       "           1.5815e-01,  6.9683e-01,  1.5095e+00, -2.8562e-01,  7.7423e-02,\n",
       "           3.4145e-01,  1.5998e+00, -9.2157e-01,  2.0405e-01,  6.8340e-01,\n",
       "           1.4767e+00, -2.1059e-01,  9.3420e-02,  3.4606e-01,  1.5553e+00,\n",
       "          -8.0398e-01,  2.0463e-01,  5.5426e-01,  1.3365e+00,  1.2360e-01,\n",
       "           5.7146e-03,  3.1970e-01,  1.3478e+00, -1.1996e-01,  4.8535e-03,\n",
       "           5.5504e-01,  1.9218e+00,  3.1134e-01,  4.2536e-04,  3.3850e-01,\n",
       "           1.9645e+00,  1.0694e-01,  6.9559e-04,  5.4551e-01,  2.4411e+00,\n",
       "           1.0905e+00,  2.0291e-05,  3.2776e-01,  2.4466e+00,  7.2243e-01,\n",
       "           1.0989e-05,  5.3574e-01,  2.5431e+00,  1.1410e+00,  1.6009e-05,\n",
       "           3.0280e-01,  2.5379e+00,  7.6563e-01,  1.5368e-05,  5.8312e-01,\n",
       "           2.5987e+00,  7.5992e-01,  1.3667e-04,  4.2895e-01,  2.6112e+00,\n",
       "           2.8196e-01,  5.5959e-05]], device='cuda:0'),\n",
       " tensor([[ 0.7019,  0.2358, -0.0794,  0.9998,  0.7011,  0.2034, -0.0620,  0.9998,\n",
       "           0.6999,  0.2022, -0.0622,  0.9998,  0.6983,  0.2009, -0.0624,  0.9998,\n",
       "           0.6988,  0.2023, -0.1077,  0.9997,  0.6961,  0.2005, -0.1077,  0.9997,\n",
       "           0.6932,  0.1987, -0.1077,  0.9997,  0.6742,  0.1987,  0.0256,  0.9999,\n",
       "           0.6694,  0.1976, -0.1785,  0.9998,  0.6880,  0.2590, -0.0437,  0.9997,\n",
       "           0.6855,  0.2563, -0.1024,  0.9998,  0.5970,  0.2984,  0.1479,  0.9993,\n",
       "           0.5997,  0.3287, -0.2754,  0.9997,  0.6287,  0.5036,  0.1889,  0.0989,\n",
       "           0.6273,  0.5535, -0.2845,  0.9631,  0.7057,  0.6203,  0.1053,  0.0942,\n",
       "           0.7434,  0.6629, -0.1462,  0.8975,  0.7379,  0.6672,  0.0953,  0.1081,\n",
       "           0.7688,  0.7033, -0.1729,  0.8593,  0.7452,  0.6669,  0.0584,  0.1124,\n",
       "           0.7753,  0.6877, -0.1553,  0.8632,  0.7295,  0.6339,  0.0836,  0.1196,\n",
       "           0.7659,  0.6732, -0.1385,  0.8468,  0.5341,  0.6013,  0.1221,  0.9829,\n",
       "           0.5340,  0.6545, -0.1218,  0.9913,  0.7412,  0.6626,  0.1796,  0.1901,\n",
       "           0.7603,  0.7293, -0.1702,  0.7932,  0.7232,  0.8903,  0.2935,  0.1313,\n",
       "           0.7378,  0.9754,  0.0071,  0.6038,  0.7005,  0.9132,  0.3010,  0.1808,\n",
       "           0.6769,  1.0136,  0.0324,  0.5726,  0.7694,  0.9560,  0.2981,  0.1470,\n",
       "           0.7543,  1.0929,  0.0727,  0.5211]], device='cuda:0'))"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1], X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "d2f1aa09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2777,  0.1344],\n",
       "        [-0.3072,  0.1519],\n",
       "        [-0.3082,  0.1338],\n",
       "        [-0.2954,  0.1430],\n",
       "        [-0.3438,  0.2145]], device='cuda:0')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get some raw outputs of our model (logits)\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits = model_0(X_test.to(device=device))\n",
    "\n",
    "y_logits[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "644c8d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fn(y_true=Y_test, y_preds=torch.argmax(torch.softmax(y_logits, dim=1), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "a5452597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.7236 | Train accuracy: 50.00% | Test loss: 0.7332 | Test accuracy: 50.00%\n",
      "Epoch: 10 | Train loss: 0.7208 | Train accuracy: 50.00% | Test loss: 0.7305 | Test accuracy: 50.00%\n",
      "Epoch: 20 | Train loss: 0.7183 | Train accuracy: 50.00% | Test loss: 0.7280 | Test accuracy: 50.00%\n",
      "Epoch: 30 | Train loss: 0.7160 | Train accuracy: 50.00% | Test loss: 0.7257 | Test accuracy: 50.00%\n",
      "Epoch: 40 | Train loss: 0.7140 | Train accuracy: 50.00% | Test loss: 0.7236 | Test accuracy: 50.00%\n",
      "Epoch: 50 | Train loss: 0.7122 | Train accuracy: 50.00% | Test loss: 0.7218 | Test accuracy: 50.00%\n",
      "Epoch: 60 | Train loss: 0.7107 | Train accuracy: 50.00% | Test loss: 0.7201 | Test accuracy: 50.00%\n",
      "Epoch: 70 | Train loss: 0.7094 | Train accuracy: 50.00% | Test loss: 0.7187 | Test accuracy: 50.00%\n",
      "Epoch: 80 | Train loss: 0.7082 | Train accuracy: 50.00% | Test loss: 0.7174 | Test accuracy: 50.00%\n",
      "Epoch: 90 | Train loss: 0.7071 | Train accuracy: 50.00% | Test loss: 0.7162 | Test accuracy: 50.00%\n",
      "Epoch: 100 | Train loss: 0.7061 | Train accuracy: 50.00% | Test loss: 0.7152 | Test accuracy: 50.00%\n",
      "Epoch: 110 | Train loss: 0.7052 | Train accuracy: 50.00% | Test loss: 0.7142 | Test accuracy: 50.00%\n",
      "Epoch: 120 | Train loss: 0.7043 | Train accuracy: 50.00% | Test loss: 0.7132 | Test accuracy: 50.00%\n",
      "Epoch: 130 | Train loss: 0.7035 | Train accuracy: 50.00% | Test loss: 0.7124 | Test accuracy: 50.00%\n",
      "Epoch: 140 | Train loss: 0.7027 | Train accuracy: 50.00% | Test loss: 0.7116 | Test accuracy: 50.00%\n",
      "Epoch: 150 | Train loss: 0.7020 | Train accuracy: 50.00% | Test loss: 0.7109 | Test accuracy: 50.00%\n",
      "Epoch: 160 | Train loss: 0.7014 | Train accuracy: 50.00% | Test loss: 0.7102 | Test accuracy: 50.00%\n",
      "Epoch: 170 | Train loss: 0.7008 | Train accuracy: 50.00% | Test loss: 0.7095 | Test accuracy: 50.00%\n",
      "Epoch: 180 | Train loss: 0.7003 | Train accuracy: 50.00% | Test loss: 0.7088 | Test accuracy: 50.00%\n",
      "Epoch: 190 | Train loss: 0.6997 | Train accuracy: 50.00% | Test loss: 0.7082 | Test accuracy: 50.00%\n",
      "Epoch: 200 | Train loss: 0.6993 | Train accuracy: 50.00% | Test loss: 0.7076 | Test accuracy: 50.00%\n",
      "Epoch: 210 | Train loss: 0.6988 | Train accuracy: 50.00% | Test loss: 0.7071 | Test accuracy: 50.00%\n",
      "Epoch: 220 | Train loss: 0.6984 | Train accuracy: 50.00% | Test loss: 0.7066 | Test accuracy: 50.00%\n",
      "Epoch: 230 | Train loss: 0.6980 | Train accuracy: 50.00% | Test loss: 0.7062 | Test accuracy: 50.00%\n",
      "Epoch: 240 | Train loss: 0.6976 | Train accuracy: 50.00% | Test loss: 0.7057 | Test accuracy: 50.00%\n",
      "Epoch: 250 | Train loss: 0.6973 | Train accuracy: 50.00% | Test loss: 0.7053 | Test accuracy: 50.00%\n",
      "Epoch: 260 | Train loss: 0.6969 | Train accuracy: 50.00% | Test loss: 0.7050 | Test accuracy: 50.00%\n",
      "Epoch: 270 | Train loss: 0.6966 | Train accuracy: 50.00% | Test loss: 0.7046 | Test accuracy: 50.00%\n",
      "Epoch: 280 | Train loss: 0.6963 | Train accuracy: 50.00% | Test loss: 0.7043 | Test accuracy: 50.00%\n",
      "Epoch: 290 | Train loss: 0.6961 | Train accuracy: 50.00% | Test loss: 0.7039 | Test accuracy: 50.00%\n",
      "Epoch: 300 | Train loss: 0.6958 | Train accuracy: 50.00% | Test loss: 0.7036 | Test accuracy: 50.00%\n",
      "Epoch: 310 | Train loss: 0.6956 | Train accuracy: 50.00% | Test loss: 0.7033 | Test accuracy: 50.00%\n",
      "Epoch: 320 | Train loss: 0.6953 | Train accuracy: 50.00% | Test loss: 0.7031 | Test accuracy: 50.00%\n",
      "Epoch: 330 | Train loss: 0.6951 | Train accuracy: 50.00% | Test loss: 0.7028 | Test accuracy: 50.00%\n",
      "Epoch: 340 | Train loss: 0.6949 | Train accuracy: 50.00% | Test loss: 0.7025 | Test accuracy: 50.00%\n",
      "Epoch: 350 | Train loss: 0.6947 | Train accuracy: 50.00% | Test loss: 0.7023 | Test accuracy: 50.00%\n",
      "Epoch: 360 | Train loss: 0.6945 | Train accuracy: 50.00% | Test loss: 0.7020 | Test accuracy: 50.00%\n",
      "Epoch: 370 | Train loss: 0.6943 | Train accuracy: 50.00% | Test loss: 0.7018 | Test accuracy: 50.00%\n",
      "Epoch: 380 | Train loss: 0.6941 | Train accuracy: 50.00% | Test loss: 0.7016 | Test accuracy: 50.00%\n",
      "Epoch: 390 | Train loss: 0.6939 | Train accuracy: 50.00% | Test loss: 0.7014 | Test accuracy: 50.00%\n",
      "Epoch: 400 | Train loss: 0.6938 | Train accuracy: 50.00% | Test loss: 0.7011 | Test accuracy: 50.00%\n",
      "Epoch: 410 | Train loss: 0.6936 | Train accuracy: 50.00% | Test loss: 0.7009 | Test accuracy: 50.00%\n",
      "Epoch: 420 | Train loss: 0.6935 | Train accuracy: 50.00% | Test loss: 0.7007 | Test accuracy: 50.00%\n",
      "Epoch: 430 | Train loss: 0.6933 | Train accuracy: 50.00% | Test loss: 0.7005 | Test accuracy: 50.00%\n",
      "Epoch: 440 | Train loss: 0.6932 | Train accuracy: 50.00% | Test loss: 0.7004 | Test accuracy: 50.00%\n",
      "Epoch: 450 | Train loss: 0.6931 | Train accuracy: 50.00% | Test loss: 0.7002 | Test accuracy: 50.00%\n",
      "Epoch: 460 | Train loss: 0.6929 | Train accuracy: 50.00% | Test loss: 0.7000 | Test accuracy: 50.00%\n",
      "Epoch: 470 | Train loss: 0.6928 | Train accuracy: 50.00% | Test loss: 0.6999 | Test accuracy: 50.00%\n",
      "Epoch: 480 | Train loss: 0.6927 | Train accuracy: 50.00% | Test loss: 0.6997 | Test accuracy: 50.00%\n",
      "Epoch: 490 | Train loss: 0.6925 | Train accuracy: 50.00% | Test loss: 0.6995 | Test accuracy: 50.00%\n",
      "Epoch: 500 | Train loss: 0.6924 | Train accuracy: 50.00% | Test loss: 0.6994 | Test accuracy: 50.00%\n",
      "Epoch: 510 | Train loss: 0.6923 | Train accuracy: 50.00% | Test loss: 0.6993 | Test accuracy: 50.00%\n",
      "Epoch: 520 | Train loss: 0.6922 | Train accuracy: 50.00% | Test loss: 0.6991 | Test accuracy: 50.00%\n",
      "Epoch: 530 | Train loss: 0.6921 | Train accuracy: 50.00% | Test loss: 0.6990 | Test accuracy: 50.00%\n",
      "Epoch: 540 | Train loss: 0.6920 | Train accuracy: 50.00% | Test loss: 0.6989 | Test accuracy: 50.00%\n",
      "Epoch: 550 | Train loss: 0.6919 | Train accuracy: 50.00% | Test loss: 0.6988 | Test accuracy: 50.00%\n",
      "Epoch: 560 | Train loss: 0.6918 | Train accuracy: 50.00% | Test loss: 0.6987 | Test accuracy: 50.00%\n",
      "Epoch: 570 | Train loss: 0.6917 | Train accuracy: 50.00% | Test loss: 0.6986 | Test accuracy: 50.00%\n",
      "Epoch: 580 | Train loss: 0.6916 | Train accuracy: 50.00% | Test loss: 0.6985 | Test accuracy: 50.00%\n",
      "Epoch: 590 | Train loss: 0.6915 | Train accuracy: 50.00% | Test loss: 0.6984 | Test accuracy: 50.00%\n",
      "Epoch: 600 | Train loss: 0.6914 | Train accuracy: 50.00% | Test loss: 0.6983 | Test accuracy: 50.00%\n",
      "Epoch: 610 | Train loss: 0.6914 | Train accuracy: 50.00% | Test loss: 0.6982 | Test accuracy: 50.00%\n",
      "Epoch: 620 | Train loss: 0.6913 | Train accuracy: 50.00% | Test loss: 0.6981 | Test accuracy: 50.00%\n",
      "Epoch: 630 | Train loss: 0.6912 | Train accuracy: 50.00% | Test loss: 0.6980 | Test accuracy: 50.00%\n",
      "Epoch: 640 | Train loss: 0.6911 | Train accuracy: 50.00% | Test loss: 0.6979 | Test accuracy: 50.00%\n",
      "Epoch: 650 | Train loss: 0.6910 | Train accuracy: 50.00% | Test loss: 0.6979 | Test accuracy: 50.00%\n",
      "Epoch: 660 | Train loss: 0.6910 | Train accuracy: 50.00% | Test loss: 0.6978 | Test accuracy: 50.00%\n",
      "Epoch: 670 | Train loss: 0.6909 | Train accuracy: 50.00% | Test loss: 0.6977 | Test accuracy: 50.00%\n",
      "Epoch: 680 | Train loss: 0.6908 | Train accuracy: 50.00% | Test loss: 0.6977 | Test accuracy: 50.00%\n",
      "Epoch: 690 | Train loss: 0.6907 | Train accuracy: 50.00% | Test loss: 0.6976 | Test accuracy: 50.00%\n",
      "Epoch: 700 | Train loss: 0.6906 | Train accuracy: 50.00% | Test loss: 0.6975 | Test accuracy: 50.00%\n",
      "Epoch: 710 | Train loss: 0.6906 | Train accuracy: 50.00% | Test loss: 0.6975 | Test accuracy: 50.00%\n",
      "Epoch: 720 | Train loss: 0.6905 | Train accuracy: 50.00% | Test loss: 0.6974 | Test accuracy: 50.00%\n",
      "Epoch: 730 | Train loss: 0.6904 | Train accuracy: 50.00% | Test loss: 0.6974 | Test accuracy: 50.00%\n",
      "Epoch: 740 | Train loss: 0.6904 | Train accuracy: 50.00% | Test loss: 0.6974 | Test accuracy: 50.00%\n",
      "Epoch: 750 | Train loss: 0.6903 | Train accuracy: 50.00% | Test loss: 0.6973 | Test accuracy: 50.00%\n",
      "Epoch: 760 | Train loss: 0.6902 | Train accuracy: 50.00% | Test loss: 0.6973 | Test accuracy: 50.00%\n",
      "Epoch: 770 | Train loss: 0.6901 | Train accuracy: 50.00% | Test loss: 0.6972 | Test accuracy: 50.00%\n",
      "Epoch: 780 | Train loss: 0.6901 | Train accuracy: 50.00% | Test loss: 0.6972 | Test accuracy: 50.00%\n",
      "Epoch: 790 | Train loss: 0.6900 | Train accuracy: 50.00% | Test loss: 0.6972 | Test accuracy: 50.00%\n",
      "Epoch: 800 | Train loss: 0.6899 | Train accuracy: 50.00% | Test loss: 0.6972 | Test accuracy: 50.00%\n",
      "Epoch: 810 | Train loss: 0.6898 | Train accuracy: 50.00% | Test loss: 0.6972 | Test accuracy: 50.00%\n",
      "Epoch: 820 | Train loss: 0.6898 | Train accuracy: 50.00% | Test loss: 0.6972 | Test accuracy: 50.00%\n",
      "Epoch: 830 | Train loss: 0.6897 | Train accuracy: 50.00% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 840 | Train loss: 0.6896 | Train accuracy: 50.00% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 850 | Train loss: 0.6895 | Train accuracy: 50.00% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 860 | Train loss: 0.6894 | Train accuracy: 50.00% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 870 | Train loss: 0.6893 | Train accuracy: 50.00% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 880 | Train loss: 0.6892 | Train accuracy: 50.00% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 890 | Train loss: 0.6892 | Train accuracy: 50.00% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 900 | Train loss: 0.6891 | Train accuracy: 50.00% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 910 | Train loss: 0.6890 | Train accuracy: 50.00% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 920 | Train loss: 0.6889 | Train accuracy: 50.00% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 930 | Train loss: 0.6889 | Train accuracy: 51.14% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 940 | Train loss: 0.6888 | Train accuracy: 51.14% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 950 | Train loss: 0.6888 | Train accuracy: 51.14% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 960 | Train loss: 0.6887 | Train accuracy: 51.14% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 970 | Train loss: 0.6886 | Train accuracy: 51.14% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 980 | Train loss: 0.6885 | Train accuracy: 51.14% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 990 | Train loss: 0.6885 | Train accuracy: 51.14% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 1000 | Train loss: 0.6884 | Train accuracy: 52.27% | Test loss: 0.6971 | Test accuracy: 50.00%\n",
      "Epoch: 1010 | Train loss: 0.6884 | Train accuracy: 53.41% | Test loss: 0.6971 | Test accuracy: 40.00%\n",
      "Epoch: 1020 | Train loss: 0.6883 | Train accuracy: 53.41% | Test loss: 0.6970 | Test accuracy: 40.00%\n",
      "Epoch: 1030 | Train loss: 0.6882 | Train accuracy: 53.41% | Test loss: 0.6970 | Test accuracy: 40.00%\n",
      "Epoch: 1040 | Train loss: 0.6882 | Train accuracy: 53.41% | Test loss: 0.6970 | Test accuracy: 40.00%\n",
      "Epoch: 1050 | Train loss: 0.6881 | Train accuracy: 53.41% | Test loss: 0.6970 | Test accuracy: 40.00%\n",
      "Epoch: 1060 | Train loss: 0.6881 | Train accuracy: 53.41% | Test loss: 0.6970 | Test accuracy: 40.00%\n",
      "Epoch: 1070 | Train loss: 0.6880 | Train accuracy: 53.41% | Test loss: 0.6970 | Test accuracy: 40.00%\n",
      "Epoch: 1080 | Train loss: 0.6879 | Train accuracy: 54.55% | Test loss: 0.6970 | Test accuracy: 40.00%\n",
      "Epoch: 1090 | Train loss: 0.6879 | Train accuracy: 54.55% | Test loss: 0.6970 | Test accuracy: 40.00%\n",
      "Epoch: 1100 | Train loss: 0.6878 | Train accuracy: 53.41% | Test loss: 0.6969 | Test accuracy: 40.00%\n",
      "Epoch: 1110 | Train loss: 0.6878 | Train accuracy: 53.41% | Test loss: 0.6969 | Test accuracy: 40.00%\n",
      "Epoch: 1120 | Train loss: 0.6877 | Train accuracy: 53.41% | Test loss: 0.6969 | Test accuracy: 40.00%\n",
      "Epoch: 1130 | Train loss: 0.6877 | Train accuracy: 53.41% | Test loss: 0.6968 | Test accuracy: 40.00%\n",
      "Epoch: 1140 | Train loss: 0.6876 | Train accuracy: 54.55% | Test loss: 0.6968 | Test accuracy: 40.00%\n",
      "Epoch: 1150 | Train loss: 0.6876 | Train accuracy: 54.55% | Test loss: 0.6968 | Test accuracy: 40.00%\n",
      "Epoch: 1160 | Train loss: 0.6875 | Train accuracy: 55.68% | Test loss: 0.6968 | Test accuracy: 40.00%\n",
      "Epoch: 1170 | Train loss: 0.6874 | Train accuracy: 55.68% | Test loss: 0.6967 | Test accuracy: 40.00%\n",
      "Epoch: 1180 | Train loss: 0.6874 | Train accuracy: 55.68% | Test loss: 0.6967 | Test accuracy: 40.00%\n",
      "Epoch: 1190 | Train loss: 0.6873 | Train accuracy: 55.68% | Test loss: 0.6967 | Test accuracy: 40.00%\n",
      "Epoch: 1200 | Train loss: 0.6873 | Train accuracy: 55.68% | Test loss: 0.6966 | Test accuracy: 30.00%\n",
      "Epoch: 1210 | Train loss: 0.6872 | Train accuracy: 55.68% | Test loss: 0.6966 | Test accuracy: 30.00%\n",
      "Epoch: 1220 | Train loss: 0.6872 | Train accuracy: 55.68% | Test loss: 0.6966 | Test accuracy: 30.00%\n",
      "Epoch: 1230 | Train loss: 0.6871 | Train accuracy: 56.82% | Test loss: 0.6965 | Test accuracy: 30.00%\n",
      "Epoch: 1240 | Train loss: 0.6871 | Train accuracy: 56.82% | Test loss: 0.6965 | Test accuracy: 30.00%\n",
      "Epoch: 1250 | Train loss: 0.6870 | Train accuracy: 59.09% | Test loss: 0.6965 | Test accuracy: 30.00%\n",
      "Epoch: 1260 | Train loss: 0.6870 | Train accuracy: 59.09% | Test loss: 0.6964 | Test accuracy: 30.00%\n",
      "Epoch: 1270 | Train loss: 0.6869 | Train accuracy: 59.09% | Test loss: 0.6964 | Test accuracy: 30.00%\n",
      "Epoch: 1280 | Train loss: 0.6868 | Train accuracy: 59.09% | Test loss: 0.6964 | Test accuracy: 30.00%\n",
      "Epoch: 1290 | Train loss: 0.6868 | Train accuracy: 59.09% | Test loss: 0.6963 | Test accuracy: 30.00%\n",
      "Epoch: 1300 | Train loss: 0.6867 | Train accuracy: 59.09% | Test loss: 0.6963 | Test accuracy: 30.00%\n",
      "Epoch: 1310 | Train loss: 0.6867 | Train accuracy: 59.09% | Test loss: 0.6963 | Test accuracy: 30.00%\n",
      "Epoch: 1320 | Train loss: 0.6866 | Train accuracy: 59.09% | Test loss: 0.6962 | Test accuracy: 30.00%\n",
      "Epoch: 1330 | Train loss: 0.6866 | Train accuracy: 59.09% | Test loss: 0.6962 | Test accuracy: 30.00%\n",
      "Epoch: 1340 | Train loss: 0.6865 | Train accuracy: 59.09% | Test loss: 0.6961 | Test accuracy: 30.00%\n",
      "Epoch: 1350 | Train loss: 0.6865 | Train accuracy: 60.23% | Test loss: 0.6961 | Test accuracy: 30.00%\n",
      "Epoch: 1360 | Train loss: 0.6864 | Train accuracy: 60.23% | Test loss: 0.6961 | Test accuracy: 30.00%\n",
      "Epoch: 1370 | Train loss: 0.6864 | Train accuracy: 60.23% | Test loss: 0.6961 | Test accuracy: 30.00%\n",
      "Epoch: 1380 | Train loss: 0.6863 | Train accuracy: 59.09% | Test loss: 0.6960 | Test accuracy: 30.00%\n",
      "Epoch: 1390 | Train loss: 0.6863 | Train accuracy: 59.09% | Test loss: 0.6960 | Test accuracy: 30.00%\n",
      "Epoch: 1400 | Train loss: 0.6862 | Train accuracy: 59.09% | Test loss: 0.6959 | Test accuracy: 30.00%\n",
      "Epoch: 1410 | Train loss: 0.6861 | Train accuracy: 59.09% | Test loss: 0.6959 | Test accuracy: 30.00%\n",
      "Epoch: 1420 | Train loss: 0.6861 | Train accuracy: 59.09% | Test loss: 0.6959 | Test accuracy: 30.00%\n",
      "Epoch: 1430 | Train loss: 0.6860 | Train accuracy: 59.09% | Test loss: 0.6958 | Test accuracy: 30.00%\n",
      "Epoch: 1440 | Train loss: 0.6860 | Train accuracy: 59.09% | Test loss: 0.6958 | Test accuracy: 30.00%\n",
      "Epoch: 1450 | Train loss: 0.6859 | Train accuracy: 57.95% | Test loss: 0.6957 | Test accuracy: 30.00%\n",
      "Epoch: 1460 | Train loss: 0.6859 | Train accuracy: 57.95% | Test loss: 0.6957 | Test accuracy: 30.00%\n",
      "Epoch: 1470 | Train loss: 0.6858 | Train accuracy: 57.95% | Test loss: 0.6957 | Test accuracy: 30.00%\n",
      "Epoch: 1480 | Train loss: 0.6858 | Train accuracy: 59.09% | Test loss: 0.6956 | Test accuracy: 30.00%\n",
      "Epoch: 1490 | Train loss: 0.6857 | Train accuracy: 59.09% | Test loss: 0.6956 | Test accuracy: 40.00%\n",
      "Epoch: 1500 | Train loss: 0.6857 | Train accuracy: 59.09% | Test loss: 0.6956 | Test accuracy: 40.00%\n",
      "Epoch: 1510 | Train loss: 0.6856 | Train accuracy: 60.23% | Test loss: 0.6955 | Test accuracy: 40.00%\n",
      "Epoch: 1520 | Train loss: 0.6856 | Train accuracy: 61.36% | Test loss: 0.6955 | Test accuracy: 40.00%\n",
      "Epoch: 1530 | Train loss: 0.6855 | Train accuracy: 61.36% | Test loss: 0.6954 | Test accuracy: 40.00%\n",
      "Epoch: 1540 | Train loss: 0.6854 | Train accuracy: 61.36% | Test loss: 0.6954 | Test accuracy: 40.00%\n",
      "Epoch: 1550 | Train loss: 0.6854 | Train accuracy: 60.23% | Test loss: 0.6954 | Test accuracy: 40.00%\n",
      "Epoch: 1560 | Train loss: 0.6853 | Train accuracy: 60.23% | Test loss: 0.6953 | Test accuracy: 40.00%\n",
      "Epoch: 1570 | Train loss: 0.6853 | Train accuracy: 60.23% | Test loss: 0.6953 | Test accuracy: 40.00%\n",
      "Epoch: 1580 | Train loss: 0.6852 | Train accuracy: 60.23% | Test loss: 0.6952 | Test accuracy: 40.00%\n",
      "Epoch: 1590 | Train loss: 0.6852 | Train accuracy: 60.23% | Test loss: 0.6952 | Test accuracy: 40.00%\n",
      "Epoch: 1600 | Train loss: 0.6851 | Train accuracy: 60.23% | Test loss: 0.6951 | Test accuracy: 40.00%\n",
      "Epoch: 1610 | Train loss: 0.6850 | Train accuracy: 60.23% | Test loss: 0.6951 | Test accuracy: 40.00%\n",
      "Epoch: 1620 | Train loss: 0.6850 | Train accuracy: 61.36% | Test loss: 0.6951 | Test accuracy: 40.00%\n",
      "Epoch: 1630 | Train loss: 0.6849 | Train accuracy: 61.36% | Test loss: 0.6950 | Test accuracy: 40.00%\n",
      "Epoch: 1640 | Train loss: 0.6849 | Train accuracy: 61.36% | Test loss: 0.6950 | Test accuracy: 40.00%\n",
      "Epoch: 1650 | Train loss: 0.6848 | Train accuracy: 61.36% | Test loss: 0.6949 | Test accuracy: 40.00%\n",
      "Epoch: 1660 | Train loss: 0.6848 | Train accuracy: 61.36% | Test loss: 0.6949 | Test accuracy: 40.00%\n",
      "Epoch: 1670 | Train loss: 0.6847 | Train accuracy: 61.36% | Test loss: 0.6949 | Test accuracy: 40.00%\n",
      "Epoch: 1680 | Train loss: 0.6846 | Train accuracy: 61.36% | Test loss: 0.6948 | Test accuracy: 40.00%\n",
      "Epoch: 1690 | Train loss: 0.6846 | Train accuracy: 61.36% | Test loss: 0.6948 | Test accuracy: 40.00%\n",
      "Epoch: 1700 | Train loss: 0.6845 | Train accuracy: 61.36% | Test loss: 0.6947 | Test accuracy: 40.00%\n",
      "Epoch: 1710 | Train loss: 0.6844 | Train accuracy: 61.36% | Test loss: 0.6947 | Test accuracy: 40.00%\n",
      "Epoch: 1720 | Train loss: 0.6844 | Train accuracy: 62.50% | Test loss: 0.6946 | Test accuracy: 40.00%\n",
      "Epoch: 1730 | Train loss: 0.6843 | Train accuracy: 62.50% | Test loss: 0.6946 | Test accuracy: 40.00%\n",
      "Epoch: 1740 | Train loss: 0.6843 | Train accuracy: 62.50% | Test loss: 0.6945 | Test accuracy: 40.00%\n",
      "Epoch: 1750 | Train loss: 0.6842 | Train accuracy: 62.50% | Test loss: 0.6945 | Test accuracy: 40.00%\n",
      "Epoch: 1760 | Train loss: 0.6841 | Train accuracy: 63.64% | Test loss: 0.6944 | Test accuracy: 40.00%\n",
      "Epoch: 1770 | Train loss: 0.6841 | Train accuracy: 63.64% | Test loss: 0.6944 | Test accuracy: 40.00%\n",
      "Epoch: 1780 | Train loss: 0.6840 | Train accuracy: 63.64% | Test loss: 0.6944 | Test accuracy: 40.00%\n",
      "Epoch: 1790 | Train loss: 0.6839 | Train accuracy: 63.64% | Test loss: 0.6943 | Test accuracy: 40.00%\n",
      "Epoch: 1800 | Train loss: 0.6839 | Train accuracy: 63.64% | Test loss: 0.6943 | Test accuracy: 40.00%\n",
      "Epoch: 1810 | Train loss: 0.6838 | Train accuracy: 63.64% | Test loss: 0.6942 | Test accuracy: 40.00%\n",
      "Epoch: 1820 | Train loss: 0.6837 | Train accuracy: 63.64% | Test loss: 0.6942 | Test accuracy: 40.00%\n",
      "Epoch: 1830 | Train loss: 0.6837 | Train accuracy: 63.64% | Test loss: 0.6941 | Test accuracy: 40.00%\n",
      "Epoch: 1840 | Train loss: 0.6836 | Train accuracy: 63.64% | Test loss: 0.6941 | Test accuracy: 40.00%\n",
      "Epoch: 1850 | Train loss: 0.6835 | Train accuracy: 63.64% | Test loss: 0.6940 | Test accuracy: 40.00%\n",
      "Epoch: 1860 | Train loss: 0.6835 | Train accuracy: 63.64% | Test loss: 0.6940 | Test accuracy: 50.00%\n",
      "Epoch: 1870 | Train loss: 0.6834 | Train accuracy: 63.64% | Test loss: 0.6940 | Test accuracy: 50.00%\n",
      "Epoch: 1880 | Train loss: 0.6833 | Train accuracy: 63.64% | Test loss: 0.6939 | Test accuracy: 50.00%\n",
      "Epoch: 1890 | Train loss: 0.6832 | Train accuracy: 64.77% | Test loss: 0.6939 | Test accuracy: 50.00%\n",
      "Epoch: 1900 | Train loss: 0.6832 | Train accuracy: 64.77% | Test loss: 0.6938 | Test accuracy: 50.00%\n",
      "Epoch: 1910 | Train loss: 0.6831 | Train accuracy: 64.77% | Test loss: 0.6938 | Test accuracy: 50.00%\n",
      "Epoch: 1920 | Train loss: 0.6830 | Train accuracy: 64.77% | Test loss: 0.6937 | Test accuracy: 50.00%\n",
      "Epoch: 1930 | Train loss: 0.6830 | Train accuracy: 64.77% | Test loss: 0.6937 | Test accuracy: 50.00%\n",
      "Epoch: 1940 | Train loss: 0.6829 | Train accuracy: 64.77% | Test loss: 0.6936 | Test accuracy: 50.00%\n",
      "Epoch: 1950 | Train loss: 0.6828 | Train accuracy: 65.91% | Test loss: 0.6936 | Test accuracy: 50.00%\n",
      "Epoch: 1960 | Train loss: 0.6828 | Train accuracy: 65.91% | Test loss: 0.6935 | Test accuracy: 50.00%\n",
      "Epoch: 1970 | Train loss: 0.6827 | Train accuracy: 65.91% | Test loss: 0.6935 | Test accuracy: 50.00%\n",
      "Epoch: 1980 | Train loss: 0.6826 | Train accuracy: 68.18% | Test loss: 0.6934 | Test accuracy: 50.00%\n",
      "Epoch: 1990 | Train loss: 0.6825 | Train accuracy: 68.18% | Test loss: 0.6934 | Test accuracy: 50.00%\n",
      "Epoch: 2000 | Train loss: 0.6825 | Train accuracy: 68.18% | Test loss: 0.6933 | Test accuracy: 50.00%\n",
      "Epoch: 2010 | Train loss: 0.6824 | Train accuracy: 68.18% | Test loss: 0.6933 | Test accuracy: 50.00%\n",
      "Epoch: 2020 | Train loss: 0.6823 | Train accuracy: 68.18% | Test loss: 0.6932 | Test accuracy: 50.00%\n",
      "Epoch: 2030 | Train loss: 0.6823 | Train accuracy: 69.32% | Test loss: 0.6932 | Test accuracy: 50.00%\n",
      "Epoch: 2040 | Train loss: 0.6822 | Train accuracy: 69.32% | Test loss: 0.6932 | Test accuracy: 50.00%\n",
      "Epoch: 2050 | Train loss: 0.6821 | Train accuracy: 69.32% | Test loss: 0.6931 | Test accuracy: 50.00%\n",
      "Epoch: 2060 | Train loss: 0.6820 | Train accuracy: 69.32% | Test loss: 0.6930 | Test accuracy: 50.00%\n",
      "Epoch: 2070 | Train loss: 0.6820 | Train accuracy: 69.32% | Test loss: 0.6930 | Test accuracy: 50.00%\n",
      "Epoch: 2080 | Train loss: 0.6819 | Train accuracy: 69.32% | Test loss: 0.6929 | Test accuracy: 50.00%\n",
      "Epoch: 2090 | Train loss: 0.6818 | Train accuracy: 69.32% | Test loss: 0.6929 | Test accuracy: 50.00%\n",
      "Epoch: 2100 | Train loss: 0.6817 | Train accuracy: 70.45% | Test loss: 0.6928 | Test accuracy: 50.00%\n",
      "Epoch: 2110 | Train loss: 0.6817 | Train accuracy: 70.45% | Test loss: 0.6928 | Test accuracy: 50.00%\n",
      "Epoch: 2120 | Train loss: 0.6816 | Train accuracy: 70.45% | Test loss: 0.6927 | Test accuracy: 50.00%\n",
      "Epoch: 2130 | Train loss: 0.6815 | Train accuracy: 70.45% | Test loss: 0.6927 | Test accuracy: 50.00%\n",
      "Epoch: 2140 | Train loss: 0.6814 | Train accuracy: 71.59% | Test loss: 0.6926 | Test accuracy: 50.00%\n",
      "Epoch: 2150 | Train loss: 0.6814 | Train accuracy: 71.59% | Test loss: 0.6926 | Test accuracy: 50.00%\n",
      "Epoch: 2160 | Train loss: 0.6813 | Train accuracy: 71.59% | Test loss: 0.6925 | Test accuracy: 50.00%\n",
      "Epoch: 2170 | Train loss: 0.6812 | Train accuracy: 73.86% | Test loss: 0.6924 | Test accuracy: 50.00%\n",
      "Epoch: 2180 | Train loss: 0.6811 | Train accuracy: 73.86% | Test loss: 0.6924 | Test accuracy: 50.00%\n",
      "Epoch: 2190 | Train loss: 0.6811 | Train accuracy: 73.86% | Test loss: 0.6923 | Test accuracy: 50.00%\n",
      "Epoch: 2200 | Train loss: 0.6810 | Train accuracy: 73.86% | Test loss: 0.6923 | Test accuracy: 50.00%\n",
      "Epoch: 2210 | Train loss: 0.6809 | Train accuracy: 73.86% | Test loss: 0.6922 | Test accuracy: 50.00%\n",
      "Epoch: 2220 | Train loss: 0.6808 | Train accuracy: 73.86% | Test loss: 0.6922 | Test accuracy: 50.00%\n",
      "Epoch: 2230 | Train loss: 0.6807 | Train accuracy: 73.86% | Test loss: 0.6921 | Test accuracy: 50.00%\n",
      "Epoch: 2240 | Train loss: 0.6807 | Train accuracy: 72.73% | Test loss: 0.6921 | Test accuracy: 50.00%\n",
      "Epoch: 2250 | Train loss: 0.6806 | Train accuracy: 72.73% | Test loss: 0.6920 | Test accuracy: 50.00%\n",
      "Epoch: 2260 | Train loss: 0.6805 | Train accuracy: 72.73% | Test loss: 0.6920 | Test accuracy: 50.00%\n",
      "Epoch: 2270 | Train loss: 0.6804 | Train accuracy: 73.86% | Test loss: 0.6919 | Test accuracy: 50.00%\n",
      "Epoch: 2280 | Train loss: 0.6803 | Train accuracy: 73.86% | Test loss: 0.6918 | Test accuracy: 50.00%\n",
      "Epoch: 2290 | Train loss: 0.6802 | Train accuracy: 73.86% | Test loss: 0.6918 | Test accuracy: 50.00%\n",
      "Epoch: 2300 | Train loss: 0.6802 | Train accuracy: 73.86% | Test loss: 0.6917 | Test accuracy: 50.00%\n",
      "Epoch: 2310 | Train loss: 0.6801 | Train accuracy: 73.86% | Test loss: 0.6917 | Test accuracy: 50.00%\n",
      "Epoch: 2320 | Train loss: 0.6800 | Train accuracy: 73.86% | Test loss: 0.6916 | Test accuracy: 50.00%\n",
      "Epoch: 2330 | Train loss: 0.6799 | Train accuracy: 75.00% | Test loss: 0.6916 | Test accuracy: 50.00%\n",
      "Epoch: 2340 | Train loss: 0.6798 | Train accuracy: 75.00% | Test loss: 0.6915 | Test accuracy: 50.00%\n",
      "Epoch: 2350 | Train loss: 0.6797 | Train accuracy: 75.00% | Test loss: 0.6915 | Test accuracy: 50.00%\n",
      "Epoch: 2360 | Train loss: 0.6796 | Train accuracy: 75.00% | Test loss: 0.6914 | Test accuracy: 50.00%\n",
      "Epoch: 2370 | Train loss: 0.6795 | Train accuracy: 76.14% | Test loss: 0.6913 | Test accuracy: 50.00%\n",
      "Epoch: 2380 | Train loss: 0.6794 | Train accuracy: 76.14% | Test loss: 0.6913 | Test accuracy: 50.00%\n",
      "Epoch: 2390 | Train loss: 0.6793 | Train accuracy: 76.14% | Test loss: 0.6912 | Test accuracy: 50.00%\n",
      "Epoch: 2400 | Train loss: 0.6793 | Train accuracy: 76.14% | Test loss: 0.6911 | Test accuracy: 50.00%\n",
      "Epoch: 2410 | Train loss: 0.6792 | Train accuracy: 76.14% | Test loss: 0.6911 | Test accuracy: 50.00%\n",
      "Epoch: 2420 | Train loss: 0.6791 | Train accuracy: 76.14% | Test loss: 0.6910 | Test accuracy: 50.00%\n",
      "Epoch: 2430 | Train loss: 0.6790 | Train accuracy: 76.14% | Test loss: 0.6909 | Test accuracy: 50.00%\n",
      "Epoch: 2440 | Train loss: 0.6789 | Train accuracy: 76.14% | Test loss: 0.6909 | Test accuracy: 50.00%\n",
      "Epoch: 2450 | Train loss: 0.6788 | Train accuracy: 76.14% | Test loss: 0.6908 | Test accuracy: 50.00%\n",
      "Epoch: 2460 | Train loss: 0.6787 | Train accuracy: 76.14% | Test loss: 0.6908 | Test accuracy: 50.00%\n",
      "Epoch: 2470 | Train loss: 0.6786 | Train accuracy: 75.00% | Test loss: 0.6907 | Test accuracy: 50.00%\n",
      "Epoch: 2480 | Train loss: 0.6785 | Train accuracy: 75.00% | Test loss: 0.6906 | Test accuracy: 50.00%\n",
      "Epoch: 2490 | Train loss: 0.6784 | Train accuracy: 75.00% | Test loss: 0.6906 | Test accuracy: 50.00%\n",
      "Epoch: 2500 | Train loss: 0.6783 | Train accuracy: 75.00% | Test loss: 0.6905 | Test accuracy: 50.00%\n",
      "Epoch: 2510 | Train loss: 0.6782 | Train accuracy: 75.00% | Test loss: 0.6905 | Test accuracy: 50.00%\n",
      "Epoch: 2520 | Train loss: 0.6781 | Train accuracy: 75.00% | Test loss: 0.6904 | Test accuracy: 50.00%\n",
      "Epoch: 2530 | Train loss: 0.6780 | Train accuracy: 75.00% | Test loss: 0.6903 | Test accuracy: 50.00%\n",
      "Epoch: 2540 | Train loss: 0.6779 | Train accuracy: 73.86% | Test loss: 0.6903 | Test accuracy: 50.00%\n",
      "Epoch: 2550 | Train loss: 0.6778 | Train accuracy: 73.86% | Test loss: 0.6902 | Test accuracy: 50.00%\n",
      "Epoch: 2560 | Train loss: 0.6777 | Train accuracy: 73.86% | Test loss: 0.6901 | Test accuracy: 50.00%\n",
      "Epoch: 2570 | Train loss: 0.6776 | Train accuracy: 73.86% | Test loss: 0.6901 | Test accuracy: 50.00%\n",
      "Epoch: 2580 | Train loss: 0.6775 | Train accuracy: 73.86% | Test loss: 0.6900 | Test accuracy: 50.00%\n",
      "Epoch: 2590 | Train loss: 0.6774 | Train accuracy: 73.86% | Test loss: 0.6899 | Test accuracy: 50.00%\n",
      "Epoch: 2600 | Train loss: 0.6773 | Train accuracy: 73.86% | Test loss: 0.6898 | Test accuracy: 50.00%\n",
      "Epoch: 2610 | Train loss: 0.6772 | Train accuracy: 73.86% | Test loss: 0.6898 | Test accuracy: 50.00%\n",
      "Epoch: 2620 | Train loss: 0.6771 | Train accuracy: 75.00% | Test loss: 0.6897 | Test accuracy: 50.00%\n",
      "Epoch: 2630 | Train loss: 0.6770 | Train accuracy: 75.00% | Test loss: 0.6896 | Test accuracy: 50.00%\n",
      "Epoch: 2640 | Train loss: 0.6769 | Train accuracy: 75.00% | Test loss: 0.6896 | Test accuracy: 50.00%\n",
      "Epoch: 2650 | Train loss: 0.6768 | Train accuracy: 75.00% | Test loss: 0.6895 | Test accuracy: 50.00%\n",
      "Epoch: 2660 | Train loss: 0.6767 | Train accuracy: 75.00% | Test loss: 0.6894 | Test accuracy: 50.00%\n",
      "Epoch: 2670 | Train loss: 0.6766 | Train accuracy: 75.00% | Test loss: 0.6893 | Test accuracy: 50.00%\n",
      "Epoch: 2680 | Train loss: 0.6765 | Train accuracy: 75.00% | Test loss: 0.6893 | Test accuracy: 50.00%\n",
      "Epoch: 2690 | Train loss: 0.6764 | Train accuracy: 75.00% | Test loss: 0.6892 | Test accuracy: 50.00%\n",
      "Epoch: 2700 | Train loss: 0.6763 | Train accuracy: 75.00% | Test loss: 0.6891 | Test accuracy: 50.00%\n",
      "Epoch: 2710 | Train loss: 0.6762 | Train accuracy: 75.00% | Test loss: 0.6891 | Test accuracy: 50.00%\n",
      "Epoch: 2720 | Train loss: 0.6761 | Train accuracy: 75.00% | Test loss: 0.6890 | Test accuracy: 50.00%\n",
      "Epoch: 2730 | Train loss: 0.6760 | Train accuracy: 75.00% | Test loss: 0.6889 | Test accuracy: 50.00%\n",
      "Epoch: 2740 | Train loss: 0.6758 | Train accuracy: 76.14% | Test loss: 0.6889 | Test accuracy: 50.00%\n",
      "Epoch: 2750 | Train loss: 0.6757 | Train accuracy: 76.14% | Test loss: 0.6888 | Test accuracy: 50.00%\n",
      "Epoch: 2760 | Train loss: 0.6756 | Train accuracy: 76.14% | Test loss: 0.6887 | Test accuracy: 50.00%\n",
      "Epoch: 2770 | Train loss: 0.6755 | Train accuracy: 76.14% | Test loss: 0.6887 | Test accuracy: 50.00%\n",
      "Epoch: 2780 | Train loss: 0.6754 | Train accuracy: 76.14% | Test loss: 0.6886 | Test accuracy: 50.00%\n",
      "Epoch: 2790 | Train loss: 0.6753 | Train accuracy: 75.00% | Test loss: 0.6885 | Test accuracy: 50.00%\n",
      "Epoch: 2800 | Train loss: 0.6752 | Train accuracy: 76.14% | Test loss: 0.6885 | Test accuracy: 50.00%\n",
      "Epoch: 2810 | Train loss: 0.6751 | Train accuracy: 76.14% | Test loss: 0.6884 | Test accuracy: 50.00%\n",
      "Epoch: 2820 | Train loss: 0.6750 | Train accuracy: 76.14% | Test loss: 0.6883 | Test accuracy: 50.00%\n",
      "Epoch: 2830 | Train loss: 0.6748 | Train accuracy: 76.14% | Test loss: 0.6882 | Test accuracy: 50.00%\n",
      "Epoch: 2840 | Train loss: 0.6747 | Train accuracy: 76.14% | Test loss: 0.6882 | Test accuracy: 50.00%\n",
      "Epoch: 2850 | Train loss: 0.6746 | Train accuracy: 76.14% | Test loss: 0.6881 | Test accuracy: 50.00%\n",
      "Epoch: 2860 | Train loss: 0.6745 | Train accuracy: 76.14% | Test loss: 0.6880 | Test accuracy: 50.00%\n",
      "Epoch: 2870 | Train loss: 0.6744 | Train accuracy: 76.14% | Test loss: 0.6879 | Test accuracy: 50.00%\n",
      "Epoch: 2880 | Train loss: 0.6743 | Train accuracy: 76.14% | Test loss: 0.6879 | Test accuracy: 50.00%\n",
      "Epoch: 2890 | Train loss: 0.6741 | Train accuracy: 76.14% | Test loss: 0.6878 | Test accuracy: 50.00%\n",
      "Epoch: 2900 | Train loss: 0.6740 | Train accuracy: 76.14% | Test loss: 0.6877 | Test accuracy: 50.00%\n",
      "Epoch: 2910 | Train loss: 0.6739 | Train accuracy: 76.14% | Test loss: 0.6876 | Test accuracy: 50.00%\n",
      "Epoch: 2920 | Train loss: 0.6738 | Train accuracy: 76.14% | Test loss: 0.6876 | Test accuracy: 50.00%\n",
      "Epoch: 2930 | Train loss: 0.6736 | Train accuracy: 76.14% | Test loss: 0.6875 | Test accuracy: 50.00%\n",
      "Epoch: 2940 | Train loss: 0.6735 | Train accuracy: 76.14% | Test loss: 0.6874 | Test accuracy: 50.00%\n",
      "Epoch: 2950 | Train loss: 0.6734 | Train accuracy: 76.14% | Test loss: 0.6873 | Test accuracy: 50.00%\n",
      "Epoch: 2960 | Train loss: 0.6733 | Train accuracy: 76.14% | Test loss: 0.6873 | Test accuracy: 50.00%\n",
      "Epoch: 2970 | Train loss: 0.6731 | Train accuracy: 76.14% | Test loss: 0.6872 | Test accuracy: 50.00%\n",
      "Epoch: 2980 | Train loss: 0.6730 | Train accuracy: 76.14% | Test loss: 0.6871 | Test accuracy: 50.00%\n",
      "Epoch: 2990 | Train loss: 0.6729 | Train accuracy: 76.14% | Test loss: 0.6870 | Test accuracy: 50.00%\n",
      "Epoch: 3000 | Train loss: 0.6727 | Train accuracy: 76.14% | Test loss: 0.6869 | Test accuracy: 60.00%\n",
      "Epoch: 3010 | Train loss: 0.6726 | Train accuracy: 76.14% | Test loss: 0.6868 | Test accuracy: 60.00%\n",
      "Epoch: 3020 | Train loss: 0.6725 | Train accuracy: 76.14% | Test loss: 0.6867 | Test accuracy: 60.00%\n",
      "Epoch: 3030 | Train loss: 0.6724 | Train accuracy: 76.14% | Test loss: 0.6867 | Test accuracy: 60.00%\n",
      "Epoch: 3040 | Train loss: 0.6722 | Train accuracy: 76.14% | Test loss: 0.6866 | Test accuracy: 60.00%\n",
      "Epoch: 3050 | Train loss: 0.6721 | Train accuracy: 76.14% | Test loss: 0.6865 | Test accuracy: 60.00%\n",
      "Epoch: 3060 | Train loss: 0.6720 | Train accuracy: 76.14% | Test loss: 0.6864 | Test accuracy: 60.00%\n",
      "Epoch: 3070 | Train loss: 0.6718 | Train accuracy: 76.14% | Test loss: 0.6863 | Test accuracy: 60.00%\n",
      "Epoch: 3080 | Train loss: 0.6717 | Train accuracy: 76.14% | Test loss: 0.6862 | Test accuracy: 60.00%\n",
      "Epoch: 3090 | Train loss: 0.6716 | Train accuracy: 76.14% | Test loss: 0.6861 | Test accuracy: 60.00%\n",
      "Epoch: 3100 | Train loss: 0.6714 | Train accuracy: 76.14% | Test loss: 0.6860 | Test accuracy: 60.00%\n",
      "Epoch: 3110 | Train loss: 0.6713 | Train accuracy: 76.14% | Test loss: 0.6859 | Test accuracy: 60.00%\n",
      "Epoch: 3120 | Train loss: 0.6712 | Train accuracy: 76.14% | Test loss: 0.6859 | Test accuracy: 60.00%\n",
      "Epoch: 3130 | Train loss: 0.6710 | Train accuracy: 76.14% | Test loss: 0.6858 | Test accuracy: 60.00%\n",
      "Epoch: 3140 | Train loss: 0.6709 | Train accuracy: 76.14% | Test loss: 0.6857 | Test accuracy: 60.00%\n",
      "Epoch: 3150 | Train loss: 0.6707 | Train accuracy: 76.14% | Test loss: 0.6856 | Test accuracy: 60.00%\n",
      "Epoch: 3160 | Train loss: 0.6706 | Train accuracy: 76.14% | Test loss: 0.6855 | Test accuracy: 60.00%\n",
      "Epoch: 3170 | Train loss: 0.6705 | Train accuracy: 76.14% | Test loss: 0.6854 | Test accuracy: 60.00%\n",
      "Epoch: 3180 | Train loss: 0.6703 | Train accuracy: 76.14% | Test loss: 0.6853 | Test accuracy: 60.00%\n",
      "Epoch: 3190 | Train loss: 0.6702 | Train accuracy: 76.14% | Test loss: 0.6852 | Test accuracy: 60.00%\n",
      "Epoch: 3200 | Train loss: 0.6700 | Train accuracy: 76.14% | Test loss: 0.6851 | Test accuracy: 60.00%\n",
      "Epoch: 3210 | Train loss: 0.6699 | Train accuracy: 76.14% | Test loss: 0.6850 | Test accuracy: 60.00%\n",
      "Epoch: 3220 | Train loss: 0.6697 | Train accuracy: 76.14% | Test loss: 0.6850 | Test accuracy: 60.00%\n",
      "Epoch: 3230 | Train loss: 0.6696 | Train accuracy: 76.14% | Test loss: 0.6849 | Test accuracy: 60.00%\n",
      "Epoch: 3240 | Train loss: 0.6694 | Train accuracy: 76.14% | Test loss: 0.6848 | Test accuracy: 60.00%\n",
      "Epoch: 3250 | Train loss: 0.6693 | Train accuracy: 76.14% | Test loss: 0.6847 | Test accuracy: 60.00%\n",
      "Epoch: 3260 | Train loss: 0.6691 | Train accuracy: 76.14% | Test loss: 0.6846 | Test accuracy: 60.00%\n",
      "Epoch: 3270 | Train loss: 0.6690 | Train accuracy: 76.14% | Test loss: 0.6846 | Test accuracy: 60.00%\n",
      "Epoch: 3280 | Train loss: 0.6688 | Train accuracy: 76.14% | Test loss: 0.6845 | Test accuracy: 60.00%\n",
      "Epoch: 3290 | Train loss: 0.6686 | Train accuracy: 75.00% | Test loss: 0.6844 | Test accuracy: 60.00%\n",
      "Epoch: 3300 | Train loss: 0.6685 | Train accuracy: 75.00% | Test loss: 0.6843 | Test accuracy: 60.00%\n",
      "Epoch: 3310 | Train loss: 0.6683 | Train accuracy: 75.00% | Test loss: 0.6842 | Test accuracy: 60.00%\n",
      "Epoch: 3320 | Train loss: 0.6682 | Train accuracy: 75.00% | Test loss: 0.6841 | Test accuracy: 60.00%\n",
      "Epoch: 3330 | Train loss: 0.6680 | Train accuracy: 76.14% | Test loss: 0.6841 | Test accuracy: 60.00%\n",
      "Epoch: 3340 | Train loss: 0.6678 | Train accuracy: 76.14% | Test loss: 0.6840 | Test accuracy: 60.00%\n",
      "Epoch: 3350 | Train loss: 0.6676 | Train accuracy: 76.14% | Test loss: 0.6839 | Test accuracy: 60.00%\n",
      "Epoch: 3360 | Train loss: 0.6675 | Train accuracy: 76.14% | Test loss: 0.6838 | Test accuracy: 60.00%\n",
      "Epoch: 3370 | Train loss: 0.6673 | Train accuracy: 76.14% | Test loss: 0.6837 | Test accuracy: 60.00%\n",
      "Epoch: 3380 | Train loss: 0.6671 | Train accuracy: 76.14% | Test loss: 0.6836 | Test accuracy: 60.00%\n",
      "Epoch: 3390 | Train loss: 0.6670 | Train accuracy: 76.14% | Test loss: 0.6835 | Test accuracy: 60.00%\n",
      "Epoch: 3400 | Train loss: 0.6668 | Train accuracy: 76.14% | Test loss: 0.6834 | Test accuracy: 60.00%\n",
      "Epoch: 3410 | Train loss: 0.6666 | Train accuracy: 76.14% | Test loss: 0.6833 | Test accuracy: 60.00%\n",
      "Epoch: 3420 | Train loss: 0.6664 | Train accuracy: 76.14% | Test loss: 0.6832 | Test accuracy: 60.00%\n",
      "Epoch: 3430 | Train loss: 0.6663 | Train accuracy: 76.14% | Test loss: 0.6831 | Test accuracy: 60.00%\n",
      "Epoch: 3440 | Train loss: 0.6661 | Train accuracy: 76.14% | Test loss: 0.6830 | Test accuracy: 60.00%\n",
      "Epoch: 3450 | Train loss: 0.6659 | Train accuracy: 76.14% | Test loss: 0.6829 | Test accuracy: 60.00%\n",
      "Epoch: 3460 | Train loss: 0.6657 | Train accuracy: 76.14% | Test loss: 0.6828 | Test accuracy: 60.00%\n",
      "Epoch: 3470 | Train loss: 0.6655 | Train accuracy: 77.27% | Test loss: 0.6827 | Test accuracy: 60.00%\n",
      "Epoch: 3480 | Train loss: 0.6653 | Train accuracy: 77.27% | Test loss: 0.6826 | Test accuracy: 60.00%\n",
      "Epoch: 3490 | Train loss: 0.6651 | Train accuracy: 77.27% | Test loss: 0.6825 | Test accuracy: 60.00%\n",
      "Epoch: 3500 | Train loss: 0.6649 | Train accuracy: 77.27% | Test loss: 0.6824 | Test accuracy: 60.00%\n",
      "Epoch: 3510 | Train loss: 0.6648 | Train accuracy: 77.27% | Test loss: 0.6823 | Test accuracy: 60.00%\n",
      "Epoch: 3520 | Train loss: 0.6646 | Train accuracy: 77.27% | Test loss: 0.6822 | Test accuracy: 60.00%\n",
      "Epoch: 3530 | Train loss: 0.6644 | Train accuracy: 77.27% | Test loss: 0.6822 | Test accuracy: 60.00%\n",
      "Epoch: 3540 | Train loss: 0.6642 | Train accuracy: 77.27% | Test loss: 0.6821 | Test accuracy: 60.00%\n",
      "Epoch: 3550 | Train loss: 0.6640 | Train accuracy: 77.27% | Test loss: 0.6820 | Test accuracy: 60.00%\n",
      "Epoch: 3560 | Train loss: 0.6638 | Train accuracy: 76.14% | Test loss: 0.6819 | Test accuracy: 60.00%\n",
      "Epoch: 3570 | Train loss: 0.6636 | Train accuracy: 76.14% | Test loss: 0.6818 | Test accuracy: 60.00%\n",
      "Epoch: 3580 | Train loss: 0.6634 | Train accuracy: 76.14% | Test loss: 0.6817 | Test accuracy: 60.00%\n",
      "Epoch: 3590 | Train loss: 0.6632 | Train accuracy: 76.14% | Test loss: 0.6815 | Test accuracy: 60.00%\n",
      "Epoch: 3600 | Train loss: 0.6630 | Train accuracy: 75.00% | Test loss: 0.6814 | Test accuracy: 60.00%\n",
      "Epoch: 3610 | Train loss: 0.6628 | Train accuracy: 75.00% | Test loss: 0.6813 | Test accuracy: 60.00%\n",
      "Epoch: 3620 | Train loss: 0.6626 | Train accuracy: 75.00% | Test loss: 0.6812 | Test accuracy: 60.00%\n",
      "Epoch: 3630 | Train loss: 0.6624 | Train accuracy: 75.00% | Test loss: 0.6811 | Test accuracy: 60.00%\n",
      "Epoch: 3640 | Train loss: 0.6622 | Train accuracy: 75.00% | Test loss: 0.6810 | Test accuracy: 60.00%\n",
      "Epoch: 3650 | Train loss: 0.6620 | Train accuracy: 75.00% | Test loss: 0.6808 | Test accuracy: 60.00%\n",
      "Epoch: 3660 | Train loss: 0.6618 | Train accuracy: 75.00% | Test loss: 0.6807 | Test accuracy: 60.00%\n",
      "Epoch: 3670 | Train loss: 0.6616 | Train accuracy: 75.00% | Test loss: 0.6806 | Test accuracy: 60.00%\n",
      "Epoch: 3680 | Train loss: 0.6614 | Train accuracy: 75.00% | Test loss: 0.6805 | Test accuracy: 60.00%\n",
      "Epoch: 3690 | Train loss: 0.6612 | Train accuracy: 75.00% | Test loss: 0.6804 | Test accuracy: 60.00%\n",
      "Epoch: 3700 | Train loss: 0.6610 | Train accuracy: 75.00% | Test loss: 0.6802 | Test accuracy: 60.00%\n",
      "Epoch: 3710 | Train loss: 0.6608 | Train accuracy: 75.00% | Test loss: 0.6801 | Test accuracy: 60.00%\n",
      "Epoch: 3720 | Train loss: 0.6606 | Train accuracy: 75.00% | Test loss: 0.6800 | Test accuracy: 60.00%\n",
      "Epoch: 3730 | Train loss: 0.6603 | Train accuracy: 75.00% | Test loss: 0.6799 | Test accuracy: 60.00%\n",
      "Epoch: 3740 | Train loss: 0.6601 | Train accuracy: 75.00% | Test loss: 0.6798 | Test accuracy: 60.00%\n",
      "Epoch: 3750 | Train loss: 0.6599 | Train accuracy: 75.00% | Test loss: 0.6796 | Test accuracy: 60.00%\n",
      "Epoch: 3760 | Train loss: 0.6597 | Train accuracy: 75.00% | Test loss: 0.6795 | Test accuracy: 60.00%\n",
      "Epoch: 3770 | Train loss: 0.6595 | Train accuracy: 75.00% | Test loss: 0.6794 | Test accuracy: 60.00%\n",
      "Epoch: 3780 | Train loss: 0.6593 | Train accuracy: 75.00% | Test loss: 0.6793 | Test accuracy: 60.00%\n",
      "Epoch: 3790 | Train loss: 0.6590 | Train accuracy: 75.00% | Test loss: 0.6792 | Test accuracy: 60.00%\n",
      "Epoch: 3800 | Train loss: 0.6588 | Train accuracy: 75.00% | Test loss: 0.6790 | Test accuracy: 60.00%\n",
      "Epoch: 3810 | Train loss: 0.6586 | Train accuracy: 75.00% | Test loss: 0.6789 | Test accuracy: 60.00%\n",
      "Epoch: 3820 | Train loss: 0.6584 | Train accuracy: 75.00% | Test loss: 0.6788 | Test accuracy: 60.00%\n",
      "Epoch: 3830 | Train loss: 0.6581 | Train accuracy: 73.86% | Test loss: 0.6787 | Test accuracy: 60.00%\n",
      "Epoch: 3840 | Train loss: 0.6579 | Train accuracy: 73.86% | Test loss: 0.6786 | Test accuracy: 60.00%\n",
      "Epoch: 3850 | Train loss: 0.6576 | Train accuracy: 73.86% | Test loss: 0.6784 | Test accuracy: 60.00%\n",
      "Epoch: 3860 | Train loss: 0.6574 | Train accuracy: 73.86% | Test loss: 0.6783 | Test accuracy: 60.00%\n",
      "Epoch: 3870 | Train loss: 0.6572 | Train accuracy: 73.86% | Test loss: 0.6782 | Test accuracy: 60.00%\n",
      "Epoch: 3880 | Train loss: 0.6569 | Train accuracy: 73.86% | Test loss: 0.6780 | Test accuracy: 60.00%\n",
      "Epoch: 3890 | Train loss: 0.6567 | Train accuracy: 73.86% | Test loss: 0.6779 | Test accuracy: 60.00%\n",
      "Epoch: 3900 | Train loss: 0.6564 | Train accuracy: 72.73% | Test loss: 0.6778 | Test accuracy: 60.00%\n",
      "Epoch: 3910 | Train loss: 0.6562 | Train accuracy: 73.86% | Test loss: 0.6776 | Test accuracy: 60.00%\n",
      "Epoch: 3920 | Train loss: 0.6559 | Train accuracy: 73.86% | Test loss: 0.6775 | Test accuracy: 60.00%\n",
      "Epoch: 3930 | Train loss: 0.6557 | Train accuracy: 72.73% | Test loss: 0.6773 | Test accuracy: 60.00%\n",
      "Epoch: 3940 | Train loss: 0.6554 | Train accuracy: 72.73% | Test loss: 0.6772 | Test accuracy: 60.00%\n",
      "Epoch: 3950 | Train loss: 0.6552 | Train accuracy: 72.73% | Test loss: 0.6770 | Test accuracy: 60.00%\n",
      "Epoch: 3960 | Train loss: 0.6549 | Train accuracy: 72.73% | Test loss: 0.6769 | Test accuracy: 60.00%\n",
      "Epoch: 3970 | Train loss: 0.6546 | Train accuracy: 72.73% | Test loss: 0.6767 | Test accuracy: 60.00%\n",
      "Epoch: 3980 | Train loss: 0.6544 | Train accuracy: 72.73% | Test loss: 0.6766 | Test accuracy: 60.00%\n",
      "Epoch: 3990 | Train loss: 0.6541 | Train accuracy: 72.73% | Test loss: 0.6764 | Test accuracy: 60.00%\n",
      "Epoch: 4000 | Train loss: 0.6538 | Train accuracy: 72.73% | Test loss: 0.6762 | Test accuracy: 60.00%\n",
      "Epoch: 4010 | Train loss: 0.6536 | Train accuracy: 72.73% | Test loss: 0.6761 | Test accuracy: 60.00%\n",
      "Epoch: 4020 | Train loss: 0.6533 | Train accuracy: 72.73% | Test loss: 0.6759 | Test accuracy: 60.00%\n",
      "Epoch: 4030 | Train loss: 0.6530 | Train accuracy: 72.73% | Test loss: 0.6758 | Test accuracy: 60.00%\n",
      "Epoch: 4040 | Train loss: 0.6528 | Train accuracy: 72.73% | Test loss: 0.6756 | Test accuracy: 60.00%\n",
      "Epoch: 4050 | Train loss: 0.6525 | Train accuracy: 72.73% | Test loss: 0.6755 | Test accuracy: 60.00%\n",
      "Epoch: 4060 | Train loss: 0.6522 | Train accuracy: 72.73% | Test loss: 0.6753 | Test accuracy: 60.00%\n",
      "Epoch: 4070 | Train loss: 0.6519 | Train accuracy: 72.73% | Test loss: 0.6751 | Test accuracy: 60.00%\n",
      "Epoch: 4080 | Train loss: 0.6517 | Train accuracy: 72.73% | Test loss: 0.6750 | Test accuracy: 60.00%\n",
      "Epoch: 4090 | Train loss: 0.6514 | Train accuracy: 72.73% | Test loss: 0.6748 | Test accuracy: 60.00%\n",
      "Epoch: 4100 | Train loss: 0.6511 | Train accuracy: 72.73% | Test loss: 0.6746 | Test accuracy: 60.00%\n",
      "Epoch: 4110 | Train loss: 0.6508 | Train accuracy: 72.73% | Test loss: 0.6745 | Test accuracy: 60.00%\n",
      "Epoch: 4120 | Train loss: 0.6505 | Train accuracy: 71.59% | Test loss: 0.6743 | Test accuracy: 60.00%\n",
      "Epoch: 4130 | Train loss: 0.6503 | Train accuracy: 71.59% | Test loss: 0.6742 | Test accuracy: 60.00%\n",
      "Epoch: 4140 | Train loss: 0.6500 | Train accuracy: 71.59% | Test loss: 0.6740 | Test accuracy: 60.00%\n",
      "Epoch: 4150 | Train loss: 0.6497 | Train accuracy: 71.59% | Test loss: 0.6739 | Test accuracy: 60.00%\n",
      "Epoch: 4160 | Train loss: 0.6494 | Train accuracy: 71.59% | Test loss: 0.6737 | Test accuracy: 60.00%\n",
      "Epoch: 4170 | Train loss: 0.6491 | Train accuracy: 71.59% | Test loss: 0.6736 | Test accuracy: 60.00%\n",
      "Epoch: 4180 | Train loss: 0.6488 | Train accuracy: 71.59% | Test loss: 0.6734 | Test accuracy: 60.00%\n",
      "Epoch: 4190 | Train loss: 0.6486 | Train accuracy: 71.59% | Test loss: 0.6733 | Test accuracy: 60.00%\n",
      "Epoch: 4200 | Train loss: 0.6483 | Train accuracy: 72.73% | Test loss: 0.6731 | Test accuracy: 60.00%\n",
      "Epoch: 4210 | Train loss: 0.6480 | Train accuracy: 72.73% | Test loss: 0.6730 | Test accuracy: 60.00%\n",
      "Epoch: 4220 | Train loss: 0.6477 | Train accuracy: 72.73% | Test loss: 0.6728 | Test accuracy: 60.00%\n",
      "Epoch: 4230 | Train loss: 0.6474 | Train accuracy: 72.73% | Test loss: 0.6726 | Test accuracy: 60.00%\n",
      "Epoch: 4240 | Train loss: 0.6471 | Train accuracy: 72.73% | Test loss: 0.6725 | Test accuracy: 60.00%\n",
      "Epoch: 4250 | Train loss: 0.6468 | Train accuracy: 72.73% | Test loss: 0.6723 | Test accuracy: 60.00%\n",
      "Epoch: 4260 | Train loss: 0.6465 | Train accuracy: 72.73% | Test loss: 0.6722 | Test accuracy: 60.00%\n",
      "Epoch: 4270 | Train loss: 0.6462 | Train accuracy: 72.73% | Test loss: 0.6720 | Test accuracy: 60.00%\n",
      "Epoch: 4280 | Train loss: 0.6459 | Train accuracy: 72.73% | Test loss: 0.6718 | Test accuracy: 60.00%\n",
      "Epoch: 4290 | Train loss: 0.6455 | Train accuracy: 72.73% | Test loss: 0.6717 | Test accuracy: 60.00%\n",
      "Epoch: 4300 | Train loss: 0.6452 | Train accuracy: 72.73% | Test loss: 0.6715 | Test accuracy: 60.00%\n",
      "Epoch: 4310 | Train loss: 0.6449 | Train accuracy: 72.73% | Test loss: 0.6713 | Test accuracy: 60.00%\n",
      "Epoch: 4320 | Train loss: 0.6446 | Train accuracy: 72.73% | Test loss: 0.6712 | Test accuracy: 60.00%\n",
      "Epoch: 4330 | Train loss: 0.6443 | Train accuracy: 72.73% | Test loss: 0.6710 | Test accuracy: 60.00%\n",
      "Epoch: 4340 | Train loss: 0.6440 | Train accuracy: 72.73% | Test loss: 0.6708 | Test accuracy: 60.00%\n",
      "Epoch: 4350 | Train loss: 0.6436 | Train accuracy: 72.73% | Test loss: 0.6706 | Test accuracy: 60.00%\n",
      "Epoch: 4360 | Train loss: 0.6433 | Train accuracy: 72.73% | Test loss: 0.6704 | Test accuracy: 60.00%\n",
      "Epoch: 4370 | Train loss: 0.6430 | Train accuracy: 72.73% | Test loss: 0.6703 | Test accuracy: 60.00%\n",
      "Epoch: 4380 | Train loss: 0.6426 | Train accuracy: 72.73% | Test loss: 0.6701 | Test accuracy: 60.00%\n",
      "Epoch: 4390 | Train loss: 0.6423 | Train accuracy: 72.73% | Test loss: 0.6699 | Test accuracy: 60.00%\n",
      "Epoch: 4400 | Train loss: 0.6420 | Train accuracy: 72.73% | Test loss: 0.6697 | Test accuracy: 60.00%\n",
      "Epoch: 4410 | Train loss: 0.6416 | Train accuracy: 72.73% | Test loss: 0.6695 | Test accuracy: 60.00%\n",
      "Epoch: 4420 | Train loss: 0.6413 | Train accuracy: 72.73% | Test loss: 0.6694 | Test accuracy: 60.00%\n",
      "Epoch: 4430 | Train loss: 0.6409 | Train accuracy: 72.73% | Test loss: 0.6692 | Test accuracy: 60.00%\n",
      "Epoch: 4440 | Train loss: 0.6406 | Train accuracy: 72.73% | Test loss: 0.6690 | Test accuracy: 60.00%\n",
      "Epoch: 4450 | Train loss: 0.6402 | Train accuracy: 73.86% | Test loss: 0.6688 | Test accuracy: 60.00%\n",
      "Epoch: 4460 | Train loss: 0.6399 | Train accuracy: 73.86% | Test loss: 0.6686 | Test accuracy: 60.00%\n",
      "Epoch: 4470 | Train loss: 0.6395 | Train accuracy: 73.86% | Test loss: 0.6685 | Test accuracy: 60.00%\n",
      "Epoch: 4480 | Train loss: 0.6392 | Train accuracy: 73.86% | Test loss: 0.6683 | Test accuracy: 60.00%\n",
      "Epoch: 4490 | Train loss: 0.6388 | Train accuracy: 73.86% | Test loss: 0.6681 | Test accuracy: 60.00%\n",
      "Epoch: 4500 | Train loss: 0.6385 | Train accuracy: 73.86% | Test loss: 0.6679 | Test accuracy: 60.00%\n",
      "Epoch: 4510 | Train loss: 0.6381 | Train accuracy: 73.86% | Test loss: 0.6678 | Test accuracy: 60.00%\n",
      "Epoch: 4520 | Train loss: 0.6378 | Train accuracy: 73.86% | Test loss: 0.6676 | Test accuracy: 60.00%\n",
      "Epoch: 4530 | Train loss: 0.6374 | Train accuracy: 73.86% | Test loss: 0.6674 | Test accuracy: 60.00%\n",
      "Epoch: 4540 | Train loss: 0.6371 | Train accuracy: 73.86% | Test loss: 0.6672 | Test accuracy: 60.00%\n",
      "Epoch: 4550 | Train loss: 0.6367 | Train accuracy: 73.86% | Test loss: 0.6671 | Test accuracy: 60.00%\n",
      "Epoch: 4560 | Train loss: 0.6363 | Train accuracy: 75.00% | Test loss: 0.6669 | Test accuracy: 60.00%\n",
      "Epoch: 4570 | Train loss: 0.6360 | Train accuracy: 76.14% | Test loss: 0.6667 | Test accuracy: 60.00%\n",
      "Epoch: 4580 | Train loss: 0.6356 | Train accuracy: 75.00% | Test loss: 0.6665 | Test accuracy: 60.00%\n",
      "Epoch: 4590 | Train loss: 0.6352 | Train accuracy: 75.00% | Test loss: 0.6663 | Test accuracy: 60.00%\n",
      "Epoch: 4600 | Train loss: 0.6349 | Train accuracy: 75.00% | Test loss: 0.6662 | Test accuracy: 60.00%\n",
      "Epoch: 4610 | Train loss: 0.6345 | Train accuracy: 75.00% | Test loss: 0.6660 | Test accuracy: 60.00%\n",
      "Epoch: 4620 | Train loss: 0.6341 | Train accuracy: 75.00% | Test loss: 0.6658 | Test accuracy: 60.00%\n",
      "Epoch: 4630 | Train loss: 0.6337 | Train accuracy: 75.00% | Test loss: 0.6656 | Test accuracy: 60.00%\n",
      "Epoch: 4640 | Train loss: 0.6333 | Train accuracy: 75.00% | Test loss: 0.6655 | Test accuracy: 60.00%\n",
      "Epoch: 4650 | Train loss: 0.6330 | Train accuracy: 75.00% | Test loss: 0.6653 | Test accuracy: 60.00%\n",
      "Epoch: 4660 | Train loss: 0.6326 | Train accuracy: 75.00% | Test loss: 0.6651 | Test accuracy: 60.00%\n",
      "Epoch: 4670 | Train loss: 0.6322 | Train accuracy: 75.00% | Test loss: 0.6649 | Test accuracy: 60.00%\n",
      "Epoch: 4680 | Train loss: 0.6318 | Train accuracy: 75.00% | Test loss: 0.6647 | Test accuracy: 60.00%\n",
      "Epoch: 4690 | Train loss: 0.6314 | Train accuracy: 75.00% | Test loss: 0.6645 | Test accuracy: 60.00%\n",
      "Epoch: 4700 | Train loss: 0.6310 | Train accuracy: 76.14% | Test loss: 0.6643 | Test accuracy: 60.00%\n",
      "Epoch: 4710 | Train loss: 0.6306 | Train accuracy: 76.14% | Test loss: 0.6641 | Test accuracy: 60.00%\n",
      "Epoch: 4720 | Train loss: 0.6302 | Train accuracy: 76.14% | Test loss: 0.6639 | Test accuracy: 60.00%\n",
      "Epoch: 4730 | Train loss: 0.6298 | Train accuracy: 77.27% | Test loss: 0.6637 | Test accuracy: 60.00%\n",
      "Epoch: 4740 | Train loss: 0.6294 | Train accuracy: 77.27% | Test loss: 0.6635 | Test accuracy: 60.00%\n",
      "Epoch: 4750 | Train loss: 0.6290 | Train accuracy: 77.27% | Test loss: 0.6633 | Test accuracy: 60.00%\n",
      "Epoch: 4760 | Train loss: 0.6286 | Train accuracy: 77.27% | Test loss: 0.6631 | Test accuracy: 60.00%\n",
      "Epoch: 4770 | Train loss: 0.6282 | Train accuracy: 77.27% | Test loss: 0.6629 | Test accuracy: 60.00%\n",
      "Epoch: 4780 | Train loss: 0.6278 | Train accuracy: 77.27% | Test loss: 0.6627 | Test accuracy: 60.00%\n",
      "Epoch: 4790 | Train loss: 0.6274 | Train accuracy: 77.27% | Test loss: 0.6625 | Test accuracy: 60.00%\n",
      "Epoch: 4800 | Train loss: 0.6270 | Train accuracy: 77.27% | Test loss: 0.6623 | Test accuracy: 60.00%\n",
      "Epoch: 4810 | Train loss: 0.6265 | Train accuracy: 77.27% | Test loss: 0.6621 | Test accuracy: 60.00%\n",
      "Epoch: 4820 | Train loss: 0.6261 | Train accuracy: 77.27% | Test loss: 0.6619 | Test accuracy: 60.00%\n",
      "Epoch: 4830 | Train loss: 0.6257 | Train accuracy: 77.27% | Test loss: 0.6617 | Test accuracy: 60.00%\n",
      "Epoch: 4840 | Train loss: 0.6253 | Train accuracy: 77.27% | Test loss: 0.6615 | Test accuracy: 60.00%\n",
      "Epoch: 4850 | Train loss: 0.6248 | Train accuracy: 77.27% | Test loss: 0.6613 | Test accuracy: 60.00%\n",
      "Epoch: 4860 | Train loss: 0.6244 | Train accuracy: 77.27% | Test loss: 0.6611 | Test accuracy: 60.00%\n",
      "Epoch: 4870 | Train loss: 0.6240 | Train accuracy: 77.27% | Test loss: 0.6609 | Test accuracy: 60.00%\n",
      "Epoch: 4880 | Train loss: 0.6235 | Train accuracy: 77.27% | Test loss: 0.6607 | Test accuracy: 60.00%\n",
      "Epoch: 4890 | Train loss: 0.6231 | Train accuracy: 77.27% | Test loss: 0.6605 | Test accuracy: 60.00%\n",
      "Epoch: 4900 | Train loss: 0.6227 | Train accuracy: 77.27% | Test loss: 0.6603 | Test accuracy: 60.00%\n",
      "Epoch: 4910 | Train loss: 0.6222 | Train accuracy: 78.41% | Test loss: 0.6601 | Test accuracy: 60.00%\n",
      "Epoch: 4920 | Train loss: 0.6218 | Train accuracy: 78.41% | Test loss: 0.6599 | Test accuracy: 60.00%\n",
      "Epoch: 4930 | Train loss: 0.6213 | Train accuracy: 78.41% | Test loss: 0.6597 | Test accuracy: 60.00%\n",
      "Epoch: 4940 | Train loss: 0.6209 | Train accuracy: 78.41% | Test loss: 0.6594 | Test accuracy: 60.00%\n",
      "Epoch: 4950 | Train loss: 0.6204 | Train accuracy: 78.41% | Test loss: 0.6592 | Test accuracy: 60.00%\n",
      "Epoch: 4960 | Train loss: 0.6200 | Train accuracy: 78.41% | Test loss: 0.6590 | Test accuracy: 60.00%\n",
      "Epoch: 4970 | Train loss: 0.6195 | Train accuracy: 78.41% | Test loss: 0.6588 | Test accuracy: 60.00%\n",
      "Epoch: 4980 | Train loss: 0.6190 | Train accuracy: 79.55% | Test loss: 0.6586 | Test accuracy: 60.00%\n",
      "Epoch: 4990 | Train loss: 0.6186 | Train accuracy: 79.55% | Test loss: 0.6583 | Test accuracy: 60.00%\n",
      "Epoch: 5000 | Train loss: 0.6181 | Train accuracy: 79.55% | Test loss: 0.6581 | Test accuracy: 60.00%\n",
      "Epoch: 5010 | Train loss: 0.6176 | Train accuracy: 79.55% | Test loss: 0.6579 | Test accuracy: 60.00%\n",
      "Epoch: 5020 | Train loss: 0.6172 | Train accuracy: 79.55% | Test loss: 0.6577 | Test accuracy: 60.00%\n",
      "Epoch: 5030 | Train loss: 0.6167 | Train accuracy: 79.55% | Test loss: 0.6575 | Test accuracy: 60.00%\n",
      "Epoch: 5040 | Train loss: 0.6162 | Train accuracy: 79.55% | Test loss: 0.6572 | Test accuracy: 60.00%\n",
      "Epoch: 5050 | Train loss: 0.6157 | Train accuracy: 79.55% | Test loss: 0.6570 | Test accuracy: 60.00%\n",
      "Epoch: 5060 | Train loss: 0.6152 | Train accuracy: 79.55% | Test loss: 0.6568 | Test accuracy: 60.00%\n",
      "Epoch: 5070 | Train loss: 0.6148 | Train accuracy: 79.55% | Test loss: 0.6566 | Test accuracy: 60.00%\n",
      "Epoch: 5080 | Train loss: 0.6143 | Train accuracy: 78.41% | Test loss: 0.6564 | Test accuracy: 60.00%\n",
      "Epoch: 5090 | Train loss: 0.6138 | Train accuracy: 78.41% | Test loss: 0.6562 | Test accuracy: 60.00%\n",
      "Epoch: 5100 | Train loss: 0.6132 | Train accuracy: 77.27% | Test loss: 0.6560 | Test accuracy: 60.00%\n",
      "Epoch: 5110 | Train loss: 0.6127 | Train accuracy: 77.27% | Test loss: 0.6558 | Test accuracy: 60.00%\n",
      "Epoch: 5120 | Train loss: 0.6122 | Train accuracy: 77.27% | Test loss: 0.6555 | Test accuracy: 60.00%\n",
      "Epoch: 5130 | Train loss: 0.6117 | Train accuracy: 78.41% | Test loss: 0.6554 | Test accuracy: 60.00%\n",
      "Epoch: 5140 | Train loss: 0.6112 | Train accuracy: 78.41% | Test loss: 0.6552 | Test accuracy: 60.00%\n",
      "Epoch: 5150 | Train loss: 0.6107 | Train accuracy: 78.41% | Test loss: 0.6550 | Test accuracy: 60.00%\n",
      "Epoch: 5160 | Train loss: 0.6102 | Train accuracy: 78.41% | Test loss: 0.6548 | Test accuracy: 60.00%\n",
      "Epoch: 5170 | Train loss: 0.6096 | Train accuracy: 78.41% | Test loss: 0.6546 | Test accuracy: 60.00%\n",
      "Epoch: 5180 | Train loss: 0.6091 | Train accuracy: 78.41% | Test loss: 0.6544 | Test accuracy: 60.00%\n",
      "Epoch: 5190 | Train loss: 0.6086 | Train accuracy: 78.41% | Test loss: 0.6542 | Test accuracy: 60.00%\n",
      "Epoch: 5200 | Train loss: 0.6080 | Train accuracy: 79.55% | Test loss: 0.6539 | Test accuracy: 60.00%\n",
      "Epoch: 5210 | Train loss: 0.6075 | Train accuracy: 79.55% | Test loss: 0.6537 | Test accuracy: 60.00%\n",
      "Epoch: 5220 | Train loss: 0.6070 | Train accuracy: 79.55% | Test loss: 0.6535 | Test accuracy: 60.00%\n",
      "Epoch: 5230 | Train loss: 0.6064 | Train accuracy: 79.55% | Test loss: 0.6533 | Test accuracy: 60.00%\n",
      "Epoch: 5240 | Train loss: 0.6059 | Train accuracy: 79.55% | Test loss: 0.6530 | Test accuracy: 60.00%\n",
      "Epoch: 5250 | Train loss: 0.6053 | Train accuracy: 79.55% | Test loss: 0.6528 | Test accuracy: 60.00%\n",
      "Epoch: 5260 | Train loss: 0.6048 | Train accuracy: 79.55% | Test loss: 0.6525 | Test accuracy: 60.00%\n",
      "Epoch: 5270 | Train loss: 0.6042 | Train accuracy: 79.55% | Test loss: 0.6523 | Test accuracy: 60.00%\n",
      "Epoch: 5280 | Train loss: 0.6037 | Train accuracy: 79.55% | Test loss: 0.6520 | Test accuracy: 60.00%\n",
      "Epoch: 5290 | Train loss: 0.6031 | Train accuracy: 79.55% | Test loss: 0.6517 | Test accuracy: 60.00%\n",
      "Epoch: 5300 | Train loss: 0.6026 | Train accuracy: 79.55% | Test loss: 0.6515 | Test accuracy: 60.00%\n",
      "Epoch: 5310 | Train loss: 0.6020 | Train accuracy: 79.55% | Test loss: 0.6512 | Test accuracy: 60.00%\n",
      "Epoch: 5320 | Train loss: 0.6014 | Train accuracy: 80.68% | Test loss: 0.6509 | Test accuracy: 60.00%\n",
      "Epoch: 5330 | Train loss: 0.6008 | Train accuracy: 80.68% | Test loss: 0.6506 | Test accuracy: 60.00%\n",
      "Epoch: 5340 | Train loss: 0.6003 | Train accuracy: 80.68% | Test loss: 0.6504 | Test accuracy: 60.00%\n",
      "Epoch: 5350 | Train loss: 0.5997 | Train accuracy: 80.68% | Test loss: 0.6501 | Test accuracy: 60.00%\n",
      "Epoch: 5360 | Train loss: 0.5991 | Train accuracy: 80.68% | Test loss: 0.6498 | Test accuracy: 60.00%\n",
      "Epoch: 5370 | Train loss: 0.5985 | Train accuracy: 80.68% | Test loss: 0.6495 | Test accuracy: 60.00%\n",
      "Epoch: 5380 | Train loss: 0.5979 | Train accuracy: 80.68% | Test loss: 0.6493 | Test accuracy: 60.00%\n",
      "Epoch: 5390 | Train loss: 0.5974 | Train accuracy: 80.68% | Test loss: 0.6490 | Test accuracy: 60.00%\n",
      "Epoch: 5400 | Train loss: 0.5968 | Train accuracy: 80.68% | Test loss: 0.6487 | Test accuracy: 60.00%\n",
      "Epoch: 5410 | Train loss: 0.5962 | Train accuracy: 80.68% | Test loss: 0.6484 | Test accuracy: 60.00%\n",
      "Epoch: 5420 | Train loss: 0.5956 | Train accuracy: 80.68% | Test loss: 0.6481 | Test accuracy: 60.00%\n",
      "Epoch: 5430 | Train loss: 0.5950 | Train accuracy: 80.68% | Test loss: 0.6478 | Test accuracy: 60.00%\n",
      "Epoch: 5440 | Train loss: 0.5944 | Train accuracy: 80.68% | Test loss: 0.6475 | Test accuracy: 60.00%\n",
      "Epoch: 5450 | Train loss: 0.5938 | Train accuracy: 80.68% | Test loss: 0.6471 | Test accuracy: 60.00%\n",
      "Epoch: 5460 | Train loss: 0.5932 | Train accuracy: 80.68% | Test loss: 0.6468 | Test accuracy: 60.00%\n",
      "Epoch: 5470 | Train loss: 0.5925 | Train accuracy: 80.68% | Test loss: 0.6465 | Test accuracy: 60.00%\n",
      "Epoch: 5480 | Train loss: 0.5919 | Train accuracy: 80.68% | Test loss: 0.6461 | Test accuracy: 60.00%\n",
      "Epoch: 5490 | Train loss: 0.5913 | Train accuracy: 80.68% | Test loss: 0.6458 | Test accuracy: 60.00%\n",
      "Epoch: 5500 | Train loss: 0.5907 | Train accuracy: 80.68% | Test loss: 0.6455 | Test accuracy: 60.00%\n",
      "Epoch: 5510 | Train loss: 0.5901 | Train accuracy: 80.68% | Test loss: 0.6451 | Test accuracy: 60.00%\n",
      "Epoch: 5520 | Train loss: 0.5894 | Train accuracy: 80.68% | Test loss: 0.6448 | Test accuracy: 60.00%\n",
      "Epoch: 5530 | Train loss: 0.5888 | Train accuracy: 80.68% | Test loss: 0.6445 | Test accuracy: 60.00%\n",
      "Epoch: 5540 | Train loss: 0.5882 | Train accuracy: 80.68% | Test loss: 0.6442 | Test accuracy: 60.00%\n",
      "Epoch: 5550 | Train loss: 0.5875 | Train accuracy: 80.68% | Test loss: 0.6439 | Test accuracy: 60.00%\n",
      "Epoch: 5560 | Train loss: 0.5869 | Train accuracy: 80.68% | Test loss: 0.6435 | Test accuracy: 60.00%\n",
      "Epoch: 5570 | Train loss: 0.5862 | Train accuracy: 80.68% | Test loss: 0.6432 | Test accuracy: 60.00%\n",
      "Epoch: 5580 | Train loss: 0.5856 | Train accuracy: 80.68% | Test loss: 0.6428 | Test accuracy: 60.00%\n",
      "Epoch: 5590 | Train loss: 0.5849 | Train accuracy: 80.68% | Test loss: 0.6425 | Test accuracy: 60.00%\n",
      "Epoch: 5600 | Train loss: 0.5843 | Train accuracy: 80.68% | Test loss: 0.6421 | Test accuracy: 60.00%\n",
      "Epoch: 5610 | Train loss: 0.5836 | Train accuracy: 79.55% | Test loss: 0.6417 | Test accuracy: 60.00%\n",
      "Epoch: 5620 | Train loss: 0.5830 | Train accuracy: 79.55% | Test loss: 0.6414 | Test accuracy: 60.00%\n",
      "Epoch: 5630 | Train loss: 0.5823 | Train accuracy: 79.55% | Test loss: 0.6410 | Test accuracy: 60.00%\n",
      "Epoch: 5640 | Train loss: 0.5816 | Train accuracy: 79.55% | Test loss: 0.6407 | Test accuracy: 60.00%\n",
      "Epoch: 5650 | Train loss: 0.5810 | Train accuracy: 79.55% | Test loss: 0.6404 | Test accuracy: 60.00%\n",
      "Epoch: 5660 | Train loss: 0.5803 | Train accuracy: 79.55% | Test loss: 0.6401 | Test accuracy: 60.00%\n",
      "Epoch: 5670 | Train loss: 0.5796 | Train accuracy: 79.55% | Test loss: 0.6397 | Test accuracy: 60.00%\n",
      "Epoch: 5680 | Train loss: 0.5790 | Train accuracy: 79.55% | Test loss: 0.6394 | Test accuracy: 60.00%\n",
      "Epoch: 5690 | Train loss: 0.5783 | Train accuracy: 79.55% | Test loss: 0.6391 | Test accuracy: 60.00%\n",
      "Epoch: 5700 | Train loss: 0.5776 | Train accuracy: 79.55% | Test loss: 0.6389 | Test accuracy: 60.00%\n",
      "Epoch: 5710 | Train loss: 0.5769 | Train accuracy: 79.55% | Test loss: 0.6386 | Test accuracy: 60.00%\n",
      "Epoch: 5720 | Train loss: 0.5763 | Train accuracy: 79.55% | Test loss: 0.6383 | Test accuracy: 60.00%\n",
      "Epoch: 5730 | Train loss: 0.5756 | Train accuracy: 79.55% | Test loss: 0.6380 | Test accuracy: 60.00%\n",
      "Epoch: 5740 | Train loss: 0.5749 | Train accuracy: 79.55% | Test loss: 0.6377 | Test accuracy: 60.00%\n",
      "Epoch: 5750 | Train loss: 0.5742 | Train accuracy: 79.55% | Test loss: 0.6374 | Test accuracy: 60.00%\n",
      "Epoch: 5760 | Train loss: 0.5735 | Train accuracy: 79.55% | Test loss: 0.6371 | Test accuracy: 60.00%\n",
      "Epoch: 5770 | Train loss: 0.5728 | Train accuracy: 79.55% | Test loss: 0.6368 | Test accuracy: 60.00%\n",
      "Epoch: 5780 | Train loss: 0.5721 | Train accuracy: 79.55% | Test loss: 0.6365 | Test accuracy: 60.00%\n",
      "Epoch: 5790 | Train loss: 0.5714 | Train accuracy: 80.68% | Test loss: 0.6362 | Test accuracy: 60.00%\n",
      "Epoch: 5800 | Train loss: 0.5707 | Train accuracy: 80.68% | Test loss: 0.6359 | Test accuracy: 60.00%\n",
      "Epoch: 5810 | Train loss: 0.5700 | Train accuracy: 80.68% | Test loss: 0.6357 | Test accuracy: 60.00%\n",
      "Epoch: 5820 | Train loss: 0.5693 | Train accuracy: 81.82% | Test loss: 0.6354 | Test accuracy: 60.00%\n",
      "Epoch: 5830 | Train loss: 0.5686 | Train accuracy: 81.82% | Test loss: 0.6351 | Test accuracy: 60.00%\n",
      "Epoch: 5840 | Train loss: 0.5678 | Train accuracy: 81.82% | Test loss: 0.6348 | Test accuracy: 60.00%\n",
      "Epoch: 5850 | Train loss: 0.5671 | Train accuracy: 81.82% | Test loss: 0.6345 | Test accuracy: 60.00%\n",
      "Epoch: 5860 | Train loss: 0.5664 | Train accuracy: 81.82% | Test loss: 0.6342 | Test accuracy: 60.00%\n",
      "Epoch: 5870 | Train loss: 0.5657 | Train accuracy: 81.82% | Test loss: 0.6339 | Test accuracy: 60.00%\n",
      "Epoch: 5880 | Train loss: 0.5650 | Train accuracy: 81.82% | Test loss: 0.6337 | Test accuracy: 60.00%\n",
      "Epoch: 5890 | Train loss: 0.5642 | Train accuracy: 81.82% | Test loss: 0.6334 | Test accuracy: 60.00%\n",
      "Epoch: 5900 | Train loss: 0.5635 | Train accuracy: 81.82% | Test loss: 0.6331 | Test accuracy: 60.00%\n",
      "Epoch: 5910 | Train loss: 0.5628 | Train accuracy: 81.82% | Test loss: 0.6328 | Test accuracy: 60.00%\n",
      "Epoch: 5920 | Train loss: 0.5620 | Train accuracy: 81.82% | Test loss: 0.6325 | Test accuracy: 60.00%\n",
      "Epoch: 5930 | Train loss: 0.5613 | Train accuracy: 81.82% | Test loss: 0.6322 | Test accuracy: 60.00%\n",
      "Epoch: 5940 | Train loss: 0.5605 | Train accuracy: 81.82% | Test loss: 0.6319 | Test accuracy: 60.00%\n",
      "Epoch: 5950 | Train loss: 0.5598 | Train accuracy: 82.95% | Test loss: 0.6316 | Test accuracy: 60.00%\n",
      "Epoch: 5960 | Train loss: 0.5590 | Train accuracy: 82.95% | Test loss: 0.6313 | Test accuracy: 60.00%\n",
      "Epoch: 5970 | Train loss: 0.5583 | Train accuracy: 82.95% | Test loss: 0.6310 | Test accuracy: 60.00%\n",
      "Epoch: 5980 | Train loss: 0.5575 | Train accuracy: 82.95% | Test loss: 0.6308 | Test accuracy: 60.00%\n",
      "Epoch: 5990 | Train loss: 0.5568 | Train accuracy: 82.95% | Test loss: 0.6305 | Test accuracy: 60.00%\n",
      "Epoch: 6000 | Train loss: 0.5560 | Train accuracy: 82.95% | Test loss: 0.6302 | Test accuracy: 60.00%\n",
      "Epoch: 6010 | Train loss: 0.5553 | Train accuracy: 82.95% | Test loss: 0.6299 | Test accuracy: 60.00%\n",
      "Epoch: 6020 | Train loss: 0.5545 | Train accuracy: 82.95% | Test loss: 0.6296 | Test accuracy: 60.00%\n",
      "Epoch: 6030 | Train loss: 0.5537 | Train accuracy: 82.95% | Test loss: 0.6293 | Test accuracy: 60.00%\n",
      "Epoch: 6040 | Train loss: 0.5530 | Train accuracy: 82.95% | Test loss: 0.6290 | Test accuracy: 60.00%\n",
      "Epoch: 6050 | Train loss: 0.5522 | Train accuracy: 82.95% | Test loss: 0.6287 | Test accuracy: 70.00%\n",
      "Epoch: 6060 | Train loss: 0.5514 | Train accuracy: 82.95% | Test loss: 0.6284 | Test accuracy: 70.00%\n",
      "Epoch: 6070 | Train loss: 0.5507 | Train accuracy: 82.95% | Test loss: 0.6282 | Test accuracy: 70.00%\n",
      "Epoch: 6080 | Train loss: 0.5499 | Train accuracy: 82.95% | Test loss: 0.6279 | Test accuracy: 70.00%\n",
      "Epoch: 6090 | Train loss: 0.5491 | Train accuracy: 82.95% | Test loss: 0.6275 | Test accuracy: 70.00%\n",
      "Epoch: 6100 | Train loss: 0.5483 | Train accuracy: 82.95% | Test loss: 0.6272 | Test accuracy: 70.00%\n",
      "Epoch: 6110 | Train loss: 0.5475 | Train accuracy: 82.95% | Test loss: 0.6269 | Test accuracy: 70.00%\n",
      "Epoch: 6120 | Train loss: 0.5467 | Train accuracy: 82.95% | Test loss: 0.6266 | Test accuracy: 70.00%\n",
      "Epoch: 6130 | Train loss: 0.5460 | Train accuracy: 82.95% | Test loss: 0.6263 | Test accuracy: 70.00%\n",
      "Epoch: 6140 | Train loss: 0.5452 | Train accuracy: 82.95% | Test loss: 0.6260 | Test accuracy: 70.00%\n",
      "Epoch: 6150 | Train loss: 0.5444 | Train accuracy: 82.95% | Test loss: 0.6257 | Test accuracy: 70.00%\n",
      "Epoch: 6160 | Train loss: 0.5436 | Train accuracy: 82.95% | Test loss: 0.6254 | Test accuracy: 70.00%\n",
      "Epoch: 6170 | Train loss: 0.5428 | Train accuracy: 82.95% | Test loss: 0.6251 | Test accuracy: 70.00%\n",
      "Epoch: 6180 | Train loss: 0.5420 | Train accuracy: 82.95% | Test loss: 0.6248 | Test accuracy: 70.00%\n",
      "Epoch: 6190 | Train loss: 0.5412 | Train accuracy: 82.95% | Test loss: 0.6245 | Test accuracy: 70.00%\n",
      "Epoch: 6200 | Train loss: 0.5404 | Train accuracy: 82.95% | Test loss: 0.6241 | Test accuracy: 70.00%\n",
      "Epoch: 6210 | Train loss: 0.5396 | Train accuracy: 82.95% | Test loss: 0.6238 | Test accuracy: 70.00%\n",
      "Epoch: 6220 | Train loss: 0.5388 | Train accuracy: 82.95% | Test loss: 0.6235 | Test accuracy: 70.00%\n",
      "Epoch: 6230 | Train loss: 0.5380 | Train accuracy: 82.95% | Test loss: 0.6232 | Test accuracy: 70.00%\n",
      "Epoch: 6240 | Train loss: 0.5372 | Train accuracy: 82.95% | Test loss: 0.6229 | Test accuracy: 70.00%\n",
      "Epoch: 6250 | Train loss: 0.5363 | Train accuracy: 82.95% | Test loss: 0.6226 | Test accuracy: 70.00%\n",
      "Epoch: 6260 | Train loss: 0.5355 | Train accuracy: 82.95% | Test loss: 0.6223 | Test accuracy: 70.00%\n",
      "Epoch: 6270 | Train loss: 0.5347 | Train accuracy: 82.95% | Test loss: 0.6220 | Test accuracy: 70.00%\n",
      "Epoch: 6280 | Train loss: 0.5339 | Train accuracy: 82.95% | Test loss: 0.6217 | Test accuracy: 70.00%\n",
      "Epoch: 6290 | Train loss: 0.5331 | Train accuracy: 82.95% | Test loss: 0.6214 | Test accuracy: 70.00%\n",
      "Epoch: 6300 | Train loss: 0.5322 | Train accuracy: 82.95% | Test loss: 0.6211 | Test accuracy: 70.00%\n",
      "Epoch: 6310 | Train loss: 0.5314 | Train accuracy: 82.95% | Test loss: 0.6208 | Test accuracy: 70.00%\n",
      "Epoch: 6320 | Train loss: 0.5306 | Train accuracy: 84.09% | Test loss: 0.6204 | Test accuracy: 70.00%\n",
      "Epoch: 6330 | Train loss: 0.5298 | Train accuracy: 84.09% | Test loss: 0.6201 | Test accuracy: 70.00%\n",
      "Epoch: 6340 | Train loss: 0.5289 | Train accuracy: 84.09% | Test loss: 0.6198 | Test accuracy: 70.00%\n",
      "Epoch: 6350 | Train loss: 0.5281 | Train accuracy: 84.09% | Test loss: 0.6195 | Test accuracy: 70.00%\n",
      "Epoch: 6360 | Train loss: 0.5273 | Train accuracy: 84.09% | Test loss: 0.6192 | Test accuracy: 70.00%\n",
      "Epoch: 6370 | Train loss: 0.5265 | Train accuracy: 84.09% | Test loss: 0.6189 | Test accuracy: 70.00%\n",
      "Epoch: 6380 | Train loss: 0.5256 | Train accuracy: 84.09% | Test loss: 0.6186 | Test accuracy: 70.00%\n",
      "Epoch: 6390 | Train loss: 0.5248 | Train accuracy: 84.09% | Test loss: 0.6183 | Test accuracy: 70.00%\n",
      "Epoch: 6400 | Train loss: 0.5239 | Train accuracy: 84.09% | Test loss: 0.6180 | Test accuracy: 70.00%\n",
      "Epoch: 6410 | Train loss: 0.5231 | Train accuracy: 84.09% | Test loss: 0.6177 | Test accuracy: 70.00%\n",
      "Epoch: 6420 | Train loss: 0.5223 | Train accuracy: 84.09% | Test loss: 0.6174 | Test accuracy: 70.00%\n",
      "Epoch: 6430 | Train loss: 0.5214 | Train accuracy: 84.09% | Test loss: 0.6171 | Test accuracy: 70.00%\n",
      "Epoch: 6440 | Train loss: 0.5206 | Train accuracy: 84.09% | Test loss: 0.6168 | Test accuracy: 70.00%\n",
      "Epoch: 6450 | Train loss: 0.5197 | Train accuracy: 84.09% | Test loss: 0.6165 | Test accuracy: 70.00%\n",
      "Epoch: 6460 | Train loss: 0.5189 | Train accuracy: 84.09% | Test loss: 0.6162 | Test accuracy: 70.00%\n",
      "Epoch: 6470 | Train loss: 0.5180 | Train accuracy: 84.09% | Test loss: 0.6159 | Test accuracy: 70.00%\n",
      "Epoch: 6480 | Train loss: 0.5172 | Train accuracy: 84.09% | Test loss: 0.6156 | Test accuracy: 70.00%\n",
      "Epoch: 6490 | Train loss: 0.5163 | Train accuracy: 84.09% | Test loss: 0.6153 | Test accuracy: 70.00%\n",
      "Epoch: 6500 | Train loss: 0.5155 | Train accuracy: 84.09% | Test loss: 0.6150 | Test accuracy: 70.00%\n",
      "Epoch: 6510 | Train loss: 0.5146 | Train accuracy: 84.09% | Test loss: 0.6147 | Test accuracy: 70.00%\n",
      "Epoch: 6520 | Train loss: 0.5138 | Train accuracy: 84.09% | Test loss: 0.6144 | Test accuracy: 70.00%\n",
      "Epoch: 6530 | Train loss: 0.5129 | Train accuracy: 84.09% | Test loss: 0.6142 | Test accuracy: 70.00%\n",
      "Epoch: 6540 | Train loss: 0.5121 | Train accuracy: 84.09% | Test loss: 0.6139 | Test accuracy: 70.00%\n",
      "Epoch: 6550 | Train loss: 0.5112 | Train accuracy: 84.09% | Test loss: 0.6136 | Test accuracy: 70.00%\n",
      "Epoch: 6560 | Train loss: 0.5103 | Train accuracy: 84.09% | Test loss: 0.6133 | Test accuracy: 70.00%\n",
      "Epoch: 6570 | Train loss: 0.5095 | Train accuracy: 84.09% | Test loss: 0.6130 | Test accuracy: 70.00%\n",
      "Epoch: 6580 | Train loss: 0.5086 | Train accuracy: 84.09% | Test loss: 0.6127 | Test accuracy: 70.00%\n",
      "Epoch: 6590 | Train loss: 0.5078 | Train accuracy: 84.09% | Test loss: 0.6124 | Test accuracy: 70.00%\n",
      "Epoch: 6600 | Train loss: 0.5069 | Train accuracy: 84.09% | Test loss: 0.6121 | Test accuracy: 70.00%\n",
      "Epoch: 6610 | Train loss: 0.5060 | Train accuracy: 84.09% | Test loss: 0.6118 | Test accuracy: 70.00%\n",
      "Epoch: 6620 | Train loss: 0.5052 | Train accuracy: 84.09% | Test loss: 0.6115 | Test accuracy: 70.00%\n",
      "Epoch: 6630 | Train loss: 0.5043 | Train accuracy: 84.09% | Test loss: 0.6113 | Test accuracy: 70.00%\n",
      "Epoch: 6640 | Train loss: 0.5034 | Train accuracy: 84.09% | Test loss: 0.6110 | Test accuracy: 70.00%\n",
      "Epoch: 6650 | Train loss: 0.5026 | Train accuracy: 84.09% | Test loss: 0.6107 | Test accuracy: 70.00%\n",
      "Epoch: 6660 | Train loss: 0.5017 | Train accuracy: 84.09% | Test loss: 0.6104 | Test accuracy: 70.00%\n",
      "Epoch: 6670 | Train loss: 0.5008 | Train accuracy: 84.09% | Test loss: 0.6101 | Test accuracy: 70.00%\n",
      "Epoch: 6680 | Train loss: 0.5000 | Train accuracy: 84.09% | Test loss: 0.6099 | Test accuracy: 70.00%\n",
      "Epoch: 6690 | Train loss: 0.4991 | Train accuracy: 84.09% | Test loss: 0.6096 | Test accuracy: 70.00%\n",
      "Epoch: 6700 | Train loss: 0.4982 | Train accuracy: 84.09% | Test loss: 0.6093 | Test accuracy: 70.00%\n",
      "Epoch: 6710 | Train loss: 0.4974 | Train accuracy: 84.09% | Test loss: 0.6091 | Test accuracy: 70.00%\n",
      "Epoch: 6720 | Train loss: 0.4965 | Train accuracy: 84.09% | Test loss: 0.6088 | Test accuracy: 70.00%\n",
      "Epoch: 6730 | Train loss: 0.4956 | Train accuracy: 84.09% | Test loss: 0.6085 | Test accuracy: 70.00%\n",
      "Epoch: 6740 | Train loss: 0.4948 | Train accuracy: 84.09% | Test loss: 0.6083 | Test accuracy: 70.00%\n",
      "Epoch: 6750 | Train loss: 0.4939 | Train accuracy: 84.09% | Test loss: 0.6080 | Test accuracy: 70.00%\n",
      "Epoch: 6760 | Train loss: 0.4930 | Train accuracy: 84.09% | Test loss: 0.6078 | Test accuracy: 70.00%\n",
      "Epoch: 6770 | Train loss: 0.4921 | Train accuracy: 84.09% | Test loss: 0.6075 | Test accuracy: 70.00%\n",
      "Epoch: 6780 | Train loss: 0.4913 | Train accuracy: 84.09% | Test loss: 0.6073 | Test accuracy: 70.00%\n",
      "Epoch: 6790 | Train loss: 0.4904 | Train accuracy: 84.09% | Test loss: 0.6070 | Test accuracy: 70.00%\n",
      "Epoch: 6800 | Train loss: 0.4895 | Train accuracy: 84.09% | Test loss: 0.6067 | Test accuracy: 70.00%\n",
      "Epoch: 6810 | Train loss: 0.4886 | Train accuracy: 84.09% | Test loss: 0.6065 | Test accuracy: 70.00%\n",
      "Epoch: 6820 | Train loss: 0.4878 | Train accuracy: 84.09% | Test loss: 0.6062 | Test accuracy: 70.00%\n",
      "Epoch: 6830 | Train loss: 0.4869 | Train accuracy: 84.09% | Test loss: 0.6060 | Test accuracy: 70.00%\n",
      "Epoch: 6840 | Train loss: 0.4860 | Train accuracy: 84.09% | Test loss: 0.6057 | Test accuracy: 70.00%\n",
      "Epoch: 6850 | Train loss: 0.4852 | Train accuracy: 84.09% | Test loss: 0.6055 | Test accuracy: 70.00%\n",
      "Epoch: 6860 | Train loss: 0.4843 | Train accuracy: 84.09% | Test loss: 0.6052 | Test accuracy: 70.00%\n",
      "Epoch: 6870 | Train loss: 0.4834 | Train accuracy: 84.09% | Test loss: 0.6050 | Test accuracy: 70.00%\n",
      "Epoch: 6880 | Train loss: 0.4825 | Train accuracy: 84.09% | Test loss: 0.6047 | Test accuracy: 70.00%\n",
      "Epoch: 6890 | Train loss: 0.4817 | Train accuracy: 84.09% | Test loss: 0.6045 | Test accuracy: 70.00%\n",
      "Epoch: 6900 | Train loss: 0.4808 | Train accuracy: 84.09% | Test loss: 0.6042 | Test accuracy: 70.00%\n",
      "Epoch: 6910 | Train loss: 0.4799 | Train accuracy: 84.09% | Test loss: 0.6040 | Test accuracy: 70.00%\n",
      "Epoch: 6920 | Train loss: 0.4790 | Train accuracy: 84.09% | Test loss: 0.6038 | Test accuracy: 70.00%\n",
      "Epoch: 6930 | Train loss: 0.4782 | Train accuracy: 84.09% | Test loss: 0.6035 | Test accuracy: 70.00%\n",
      "Epoch: 6940 | Train loss: 0.4773 | Train accuracy: 84.09% | Test loss: 0.6033 | Test accuracy: 70.00%\n",
      "Epoch: 6950 | Train loss: 0.4764 | Train accuracy: 84.09% | Test loss: 0.6030 | Test accuracy: 70.00%\n",
      "Epoch: 6960 | Train loss: 0.4755 | Train accuracy: 84.09% | Test loss: 0.6028 | Test accuracy: 70.00%\n",
      "Epoch: 6970 | Train loss: 0.4747 | Train accuracy: 84.09% | Test loss: 0.6026 | Test accuracy: 70.00%\n",
      "Epoch: 6980 | Train loss: 0.4738 | Train accuracy: 84.09% | Test loss: 0.6023 | Test accuracy: 70.00%\n",
      "Epoch: 6990 | Train loss: 0.4729 | Train accuracy: 84.09% | Test loss: 0.6021 | Test accuracy: 70.00%\n",
      "Epoch: 7000 | Train loss: 0.4720 | Train accuracy: 84.09% | Test loss: 0.6019 | Test accuracy: 70.00%\n",
      "Epoch: 7010 | Train loss: 0.4712 | Train accuracy: 84.09% | Test loss: 0.6016 | Test accuracy: 70.00%\n",
      "Epoch: 7020 | Train loss: 0.4703 | Train accuracy: 84.09% | Test loss: 0.6014 | Test accuracy: 70.00%\n",
      "Epoch: 7030 | Train loss: 0.4694 | Train accuracy: 84.09% | Test loss: 0.6012 | Test accuracy: 70.00%\n",
      "Epoch: 7040 | Train loss: 0.4685 | Train accuracy: 84.09% | Test loss: 0.6010 | Test accuracy: 70.00%\n",
      "Epoch: 7050 | Train loss: 0.4677 | Train accuracy: 84.09% | Test loss: 0.6007 | Test accuracy: 70.00%\n",
      "Epoch: 7060 | Train loss: 0.4668 | Train accuracy: 85.23% | Test loss: 0.6005 | Test accuracy: 70.00%\n",
      "Epoch: 7070 | Train loss: 0.4659 | Train accuracy: 85.23% | Test loss: 0.6003 | Test accuracy: 70.00%\n",
      "Epoch: 7080 | Train loss: 0.4651 | Train accuracy: 85.23% | Test loss: 0.6001 | Test accuracy: 70.00%\n",
      "Epoch: 7090 | Train loss: 0.4642 | Train accuracy: 85.23% | Test loss: 0.5999 | Test accuracy: 70.00%\n",
      "Epoch: 7100 | Train loss: 0.4633 | Train accuracy: 85.23% | Test loss: 0.5996 | Test accuracy: 70.00%\n",
      "Epoch: 7110 | Train loss: 0.4625 | Train accuracy: 85.23% | Test loss: 0.5994 | Test accuracy: 70.00%\n",
      "Epoch: 7120 | Train loss: 0.4616 | Train accuracy: 85.23% | Test loss: 0.5992 | Test accuracy: 70.00%\n",
      "Epoch: 7130 | Train loss: 0.4607 | Train accuracy: 85.23% | Test loss: 0.5990 | Test accuracy: 70.00%\n",
      "Epoch: 7140 | Train loss: 0.4599 | Train accuracy: 85.23% | Test loss: 0.5988 | Test accuracy: 70.00%\n",
      "Epoch: 7150 | Train loss: 0.4590 | Train accuracy: 85.23% | Test loss: 0.5986 | Test accuracy: 70.00%\n",
      "Epoch: 7160 | Train loss: 0.4581 | Train accuracy: 85.23% | Test loss: 0.5984 | Test accuracy: 70.00%\n",
      "Epoch: 7170 | Train loss: 0.4573 | Train accuracy: 85.23% | Test loss: 0.5981 | Test accuracy: 70.00%\n",
      "Epoch: 7180 | Train loss: 0.4564 | Train accuracy: 85.23% | Test loss: 0.5979 | Test accuracy: 70.00%\n",
      "Epoch: 7190 | Train loss: 0.4555 | Train accuracy: 85.23% | Test loss: 0.5977 | Test accuracy: 70.00%\n",
      "Epoch: 7200 | Train loss: 0.4547 | Train accuracy: 85.23% | Test loss: 0.5975 | Test accuracy: 70.00%\n",
      "Epoch: 7210 | Train loss: 0.4538 | Train accuracy: 85.23% | Test loss: 0.5973 | Test accuracy: 70.00%\n",
      "Epoch: 7220 | Train loss: 0.4529 | Train accuracy: 85.23% | Test loss: 0.5971 | Test accuracy: 70.00%\n",
      "Epoch: 7230 | Train loss: 0.4521 | Train accuracy: 85.23% | Test loss: 0.5969 | Test accuracy: 70.00%\n",
      "Epoch: 7240 | Train loss: 0.4512 | Train accuracy: 86.36% | Test loss: 0.5967 | Test accuracy: 70.00%\n",
      "Epoch: 7250 | Train loss: 0.4504 | Train accuracy: 86.36% | Test loss: 0.5965 | Test accuracy: 70.00%\n",
      "Epoch: 7260 | Train loss: 0.4495 | Train accuracy: 86.36% | Test loss: 0.5963 | Test accuracy: 70.00%\n",
      "Epoch: 7270 | Train loss: 0.4486 | Train accuracy: 86.36% | Test loss: 0.5961 | Test accuracy: 70.00%\n",
      "Epoch: 7280 | Train loss: 0.4478 | Train accuracy: 86.36% | Test loss: 0.5959 | Test accuracy: 70.00%\n",
      "Epoch: 7290 | Train loss: 0.4469 | Train accuracy: 86.36% | Test loss: 0.5957 | Test accuracy: 70.00%\n",
      "Epoch: 7300 | Train loss: 0.4461 | Train accuracy: 86.36% | Test loss: 0.5956 | Test accuracy: 70.00%\n",
      "Epoch: 7310 | Train loss: 0.4452 | Train accuracy: 86.36% | Test loss: 0.5954 | Test accuracy: 70.00%\n",
      "Epoch: 7320 | Train loss: 0.4444 | Train accuracy: 88.64% | Test loss: 0.5952 | Test accuracy: 70.00%\n",
      "Epoch: 7330 | Train loss: 0.4435 | Train accuracy: 88.64% | Test loss: 0.5950 | Test accuracy: 70.00%\n",
      "Epoch: 7340 | Train loss: 0.4427 | Train accuracy: 88.64% | Test loss: 0.5948 | Test accuracy: 70.00%\n",
      "Epoch: 7350 | Train loss: 0.4418 | Train accuracy: 88.64% | Test loss: 0.5946 | Test accuracy: 70.00%\n",
      "Epoch: 7360 | Train loss: 0.4410 | Train accuracy: 88.64% | Test loss: 0.5945 | Test accuracy: 70.00%\n",
      "Epoch: 7370 | Train loss: 0.4401 | Train accuracy: 88.64% | Test loss: 0.5943 | Test accuracy: 70.00%\n",
      "Epoch: 7380 | Train loss: 0.4393 | Train accuracy: 88.64% | Test loss: 0.5941 | Test accuracy: 70.00%\n",
      "Epoch: 7390 | Train loss: 0.4384 | Train accuracy: 88.64% | Test loss: 0.5939 | Test accuracy: 70.00%\n",
      "Epoch: 7400 | Train loss: 0.4376 | Train accuracy: 88.64% | Test loss: 0.5938 | Test accuracy: 70.00%\n",
      "Epoch: 7410 | Train loss: 0.4367 | Train accuracy: 88.64% | Test loss: 0.5936 | Test accuracy: 70.00%\n",
      "Epoch: 7420 | Train loss: 0.4359 | Train accuracy: 88.64% | Test loss: 0.5934 | Test accuracy: 70.00%\n",
      "Epoch: 7430 | Train loss: 0.4350 | Train accuracy: 88.64% | Test loss: 0.5933 | Test accuracy: 70.00%\n",
      "Epoch: 7440 | Train loss: 0.4342 | Train accuracy: 88.64% | Test loss: 0.5931 | Test accuracy: 70.00%\n",
      "Epoch: 7450 | Train loss: 0.4334 | Train accuracy: 88.64% | Test loss: 0.5929 | Test accuracy: 70.00%\n",
      "Epoch: 7460 | Train loss: 0.4325 | Train accuracy: 88.64% | Test loss: 0.5928 | Test accuracy: 70.00%\n",
      "Epoch: 7470 | Train loss: 0.4317 | Train accuracy: 88.64% | Test loss: 0.5926 | Test accuracy: 70.00%\n",
      "Epoch: 7480 | Train loss: 0.4308 | Train accuracy: 88.64% | Test loss: 0.5924 | Test accuracy: 70.00%\n",
      "Epoch: 7490 | Train loss: 0.4300 | Train accuracy: 88.64% | Test loss: 0.5922 | Test accuracy: 70.00%\n",
      "Epoch: 7500 | Train loss: 0.4292 | Train accuracy: 88.64% | Test loss: 0.5921 | Test accuracy: 70.00%\n",
      "Epoch: 7510 | Train loss: 0.4283 | Train accuracy: 88.64% | Test loss: 0.5919 | Test accuracy: 70.00%\n",
      "Epoch: 7520 | Train loss: 0.4275 | Train accuracy: 88.64% | Test loss: 0.5917 | Test accuracy: 70.00%\n",
      "Epoch: 7530 | Train loss: 0.4267 | Train accuracy: 88.64% | Test loss: 0.5915 | Test accuracy: 70.00%\n",
      "Epoch: 7540 | Train loss: 0.4258 | Train accuracy: 88.64% | Test loss: 0.5914 | Test accuracy: 70.00%\n",
      "Epoch: 7550 | Train loss: 0.4250 | Train accuracy: 88.64% | Test loss: 0.5912 | Test accuracy: 70.00%\n",
      "Epoch: 7560 | Train loss: 0.4242 | Train accuracy: 88.64% | Test loss: 0.5910 | Test accuracy: 70.00%\n",
      "Epoch: 7570 | Train loss: 0.4234 | Train accuracy: 88.64% | Test loss: 0.5908 | Test accuracy: 70.00%\n",
      "Epoch: 7580 | Train loss: 0.4225 | Train accuracy: 88.64% | Test loss: 0.5907 | Test accuracy: 70.00%\n",
      "Epoch: 7590 | Train loss: 0.4217 | Train accuracy: 88.64% | Test loss: 0.5905 | Test accuracy: 70.00%\n",
      "Epoch: 7600 | Train loss: 0.4209 | Train accuracy: 88.64% | Test loss: 0.5903 | Test accuracy: 70.00%\n",
      "Epoch: 7610 | Train loss: 0.4201 | Train accuracy: 88.64% | Test loss: 0.5902 | Test accuracy: 70.00%\n",
      "Epoch: 7620 | Train loss: 0.4193 | Train accuracy: 88.64% | Test loss: 0.5900 | Test accuracy: 70.00%\n",
      "Epoch: 7630 | Train loss: 0.4184 | Train accuracy: 88.64% | Test loss: 0.5898 | Test accuracy: 70.00%\n",
      "Epoch: 7640 | Train loss: 0.4176 | Train accuracy: 88.64% | Test loss: 0.5896 | Test accuracy: 70.00%\n",
      "Epoch: 7650 | Train loss: 0.4168 | Train accuracy: 88.64% | Test loss: 0.5895 | Test accuracy: 70.00%\n",
      "Epoch: 7660 | Train loss: 0.4160 | Train accuracy: 88.64% | Test loss: 0.5893 | Test accuracy: 70.00%\n",
      "Epoch: 7670 | Train loss: 0.4152 | Train accuracy: 88.64% | Test loss: 0.5891 | Test accuracy: 70.00%\n",
      "Epoch: 7680 | Train loss: 0.4144 | Train accuracy: 88.64% | Test loss: 0.5890 | Test accuracy: 70.00%\n",
      "Epoch: 7690 | Train loss: 0.4136 | Train accuracy: 88.64% | Test loss: 0.5888 | Test accuracy: 70.00%\n",
      "Epoch: 7700 | Train loss: 0.4128 | Train accuracy: 88.64% | Test loss: 0.5886 | Test accuracy: 70.00%\n",
      "Epoch: 7710 | Train loss: 0.4119 | Train accuracy: 88.64% | Test loss: 0.5885 | Test accuracy: 70.00%\n",
      "Epoch: 7720 | Train loss: 0.4111 | Train accuracy: 88.64% | Test loss: 0.5883 | Test accuracy: 70.00%\n",
      "Epoch: 7730 | Train loss: 0.4103 | Train accuracy: 88.64% | Test loss: 0.5881 | Test accuracy: 70.00%\n",
      "Epoch: 7740 | Train loss: 0.4095 | Train accuracy: 88.64% | Test loss: 0.5880 | Test accuracy: 70.00%\n",
      "Epoch: 7750 | Train loss: 0.4087 | Train accuracy: 87.50% | Test loss: 0.5878 | Test accuracy: 70.00%\n",
      "Epoch: 7760 | Train loss: 0.4079 | Train accuracy: 87.50% | Test loss: 0.5877 | Test accuracy: 70.00%\n",
      "Epoch: 7770 | Train loss: 0.4071 | Train accuracy: 87.50% | Test loss: 0.5875 | Test accuracy: 70.00%\n",
      "Epoch: 7780 | Train loss: 0.4063 | Train accuracy: 87.50% | Test loss: 0.5873 | Test accuracy: 70.00%\n",
      "Epoch: 7790 | Train loss: 0.4056 | Train accuracy: 87.50% | Test loss: 0.5872 | Test accuracy: 70.00%\n",
      "Epoch: 7800 | Train loss: 0.4048 | Train accuracy: 87.50% | Test loss: 0.5870 | Test accuracy: 70.00%\n",
      "Epoch: 7810 | Train loss: 0.4040 | Train accuracy: 87.50% | Test loss: 0.5869 | Test accuracy: 70.00%\n",
      "Epoch: 7820 | Train loss: 0.4032 | Train accuracy: 87.50% | Test loss: 0.5867 | Test accuracy: 70.00%\n",
      "Epoch: 7830 | Train loss: 0.4024 | Train accuracy: 87.50% | Test loss: 0.5866 | Test accuracy: 70.00%\n",
      "Epoch: 7840 | Train loss: 0.4016 | Train accuracy: 87.50% | Test loss: 0.5864 | Test accuracy: 70.00%\n",
      "Epoch: 7850 | Train loss: 0.4008 | Train accuracy: 87.50% | Test loss: 0.5862 | Test accuracy: 70.00%\n",
      "Epoch: 7860 | Train loss: 0.4000 | Train accuracy: 87.50% | Test loss: 0.5861 | Test accuracy: 70.00%\n",
      "Epoch: 7870 | Train loss: 0.3993 | Train accuracy: 87.50% | Test loss: 0.5859 | Test accuracy: 70.00%\n",
      "Epoch: 7880 | Train loss: 0.3985 | Train accuracy: 87.50% | Test loss: 0.5858 | Test accuracy: 70.00%\n",
      "Epoch: 7890 | Train loss: 0.3977 | Train accuracy: 87.50% | Test loss: 0.5856 | Test accuracy: 70.00%\n",
      "Epoch: 7900 | Train loss: 0.3969 | Train accuracy: 87.50% | Test loss: 0.5854 | Test accuracy: 70.00%\n",
      "Epoch: 7910 | Train loss: 0.3961 | Train accuracy: 87.50% | Test loss: 0.5852 | Test accuracy: 70.00%\n",
      "Epoch: 7920 | Train loss: 0.3954 | Train accuracy: 87.50% | Test loss: 0.5851 | Test accuracy: 70.00%\n",
      "Epoch: 7930 | Train loss: 0.3946 | Train accuracy: 87.50% | Test loss: 0.5849 | Test accuracy: 70.00%\n",
      "Epoch: 7940 | Train loss: 0.3938 | Train accuracy: 87.50% | Test loss: 0.5847 | Test accuracy: 70.00%\n",
      "Epoch: 7950 | Train loss: 0.3931 | Train accuracy: 87.50% | Test loss: 0.5846 | Test accuracy: 70.00%\n",
      "Epoch: 7960 | Train loss: 0.3923 | Train accuracy: 87.50% | Test loss: 0.5844 | Test accuracy: 70.00%\n",
      "Epoch: 7970 | Train loss: 0.3915 | Train accuracy: 87.50% | Test loss: 0.5842 | Test accuracy: 70.00%\n",
      "Epoch: 7980 | Train loss: 0.3908 | Train accuracy: 87.50% | Test loss: 0.5840 | Test accuracy: 70.00%\n",
      "Epoch: 7990 | Train loss: 0.3900 | Train accuracy: 87.50% | Test loss: 0.5839 | Test accuracy: 70.00%\n",
      "Epoch: 8000 | Train loss: 0.3892 | Train accuracy: 87.50% | Test loss: 0.5837 | Test accuracy: 70.00%\n",
      "Epoch: 8010 | Train loss: 0.3885 | Train accuracy: 87.50% | Test loss: 0.5835 | Test accuracy: 70.00%\n",
      "Epoch: 8020 | Train loss: 0.3877 | Train accuracy: 87.50% | Test loss: 0.5833 | Test accuracy: 70.00%\n",
      "Epoch: 8030 | Train loss: 0.3870 | Train accuracy: 87.50% | Test loss: 0.5831 | Test accuracy: 70.00%\n",
      "Epoch: 8040 | Train loss: 0.3862 | Train accuracy: 87.50% | Test loss: 0.5830 | Test accuracy: 70.00%\n",
      "Epoch: 8050 | Train loss: 0.3855 | Train accuracy: 87.50% | Test loss: 0.5828 | Test accuracy: 70.00%\n",
      "Epoch: 8060 | Train loss: 0.3847 | Train accuracy: 87.50% | Test loss: 0.5826 | Test accuracy: 70.00%\n",
      "Epoch: 8070 | Train loss: 0.3840 | Train accuracy: 87.50% | Test loss: 0.5824 | Test accuracy: 70.00%\n",
      "Epoch: 8080 | Train loss: 0.3832 | Train accuracy: 87.50% | Test loss: 0.5822 | Test accuracy: 70.00%\n",
      "Epoch: 8090 | Train loss: 0.3825 | Train accuracy: 87.50% | Test loss: 0.5820 | Test accuracy: 70.00%\n",
      "Epoch: 8100 | Train loss: 0.3817 | Train accuracy: 87.50% | Test loss: 0.5818 | Test accuracy: 70.00%\n",
      "Epoch: 8110 | Train loss: 0.3810 | Train accuracy: 87.50% | Test loss: 0.5816 | Test accuracy: 70.00%\n",
      "Epoch: 8120 | Train loss: 0.3802 | Train accuracy: 87.50% | Test loss: 0.5814 | Test accuracy: 70.00%\n",
      "Epoch: 8130 | Train loss: 0.3795 | Train accuracy: 87.50% | Test loss: 0.5813 | Test accuracy: 70.00%\n",
      "Epoch: 8140 | Train loss: 0.3787 | Train accuracy: 87.50% | Test loss: 0.5811 | Test accuracy: 70.00%\n",
      "Epoch: 8150 | Train loss: 0.3780 | Train accuracy: 87.50% | Test loss: 0.5809 | Test accuracy: 70.00%\n",
      "Epoch: 8160 | Train loss: 0.3773 | Train accuracy: 87.50% | Test loss: 0.5807 | Test accuracy: 70.00%\n",
      "Epoch: 8170 | Train loss: 0.3765 | Train accuracy: 87.50% | Test loss: 0.5805 | Test accuracy: 70.00%\n",
      "Epoch: 8180 | Train loss: 0.3758 | Train accuracy: 87.50% | Test loss: 0.5803 | Test accuracy: 70.00%\n",
      "Epoch: 8190 | Train loss: 0.3751 | Train accuracy: 87.50% | Test loss: 0.5801 | Test accuracy: 70.00%\n",
      "Epoch: 8200 | Train loss: 0.3743 | Train accuracy: 87.50% | Test loss: 0.5799 | Test accuracy: 70.00%\n",
      "Epoch: 8210 | Train loss: 0.3736 | Train accuracy: 87.50% | Test loss: 0.5797 | Test accuracy: 70.00%\n",
      "Epoch: 8220 | Train loss: 0.3729 | Train accuracy: 87.50% | Test loss: 0.5795 | Test accuracy: 70.00%\n",
      "Epoch: 8230 | Train loss: 0.3722 | Train accuracy: 87.50% | Test loss: 0.5793 | Test accuracy: 70.00%\n",
      "Epoch: 8240 | Train loss: 0.3714 | Train accuracy: 87.50% | Test loss: 0.5791 | Test accuracy: 70.00%\n",
      "Epoch: 8250 | Train loss: 0.3707 | Train accuracy: 87.50% | Test loss: 0.5789 | Test accuracy: 70.00%\n",
      "Epoch: 8260 | Train loss: 0.3700 | Train accuracy: 87.50% | Test loss: 0.5787 | Test accuracy: 70.00%\n",
      "Epoch: 8270 | Train loss: 0.3693 | Train accuracy: 87.50% | Test loss: 0.5784 | Test accuracy: 70.00%\n",
      "Epoch: 8280 | Train loss: 0.3686 | Train accuracy: 87.50% | Test loss: 0.5782 | Test accuracy: 70.00%\n",
      "Epoch: 8290 | Train loss: 0.3678 | Train accuracy: 87.50% | Test loss: 0.5780 | Test accuracy: 70.00%\n",
      "Epoch: 8300 | Train loss: 0.3671 | Train accuracy: 87.50% | Test loss: 0.5778 | Test accuracy: 70.00%\n",
      "Epoch: 8310 | Train loss: 0.3664 | Train accuracy: 87.50% | Test loss: 0.5776 | Test accuracy: 70.00%\n",
      "Epoch: 8320 | Train loss: 0.3657 | Train accuracy: 87.50% | Test loss: 0.5774 | Test accuracy: 70.00%\n",
      "Epoch: 8330 | Train loss: 0.3650 | Train accuracy: 87.50% | Test loss: 0.5772 | Test accuracy: 70.00%\n",
      "Epoch: 8340 | Train loss: 0.3643 | Train accuracy: 87.50% | Test loss: 0.5769 | Test accuracy: 70.00%\n",
      "Epoch: 8350 | Train loss: 0.3636 | Train accuracy: 87.50% | Test loss: 0.5767 | Test accuracy: 70.00%\n",
      "Epoch: 8360 | Train loss: 0.3629 | Train accuracy: 87.50% | Test loss: 0.5766 | Test accuracy: 70.00%\n",
      "Epoch: 8370 | Train loss: 0.3621 | Train accuracy: 87.50% | Test loss: 0.5764 | Test accuracy: 70.00%\n",
      "Epoch: 8380 | Train loss: 0.3614 | Train accuracy: 87.50% | Test loss: 0.5762 | Test accuracy: 70.00%\n",
      "Epoch: 8390 | Train loss: 0.3607 | Train accuracy: 87.50% | Test loss: 0.5760 | Test accuracy: 70.00%\n",
      "Epoch: 8400 | Train loss: 0.3600 | Train accuracy: 87.50% | Test loss: 0.5758 | Test accuracy: 70.00%\n",
      "Epoch: 8410 | Train loss: 0.3593 | Train accuracy: 87.50% | Test loss: 0.5756 | Test accuracy: 70.00%\n",
      "Epoch: 8420 | Train loss: 0.3586 | Train accuracy: 87.50% | Test loss: 0.5754 | Test accuracy: 70.00%\n",
      "Epoch: 8430 | Train loss: 0.3579 | Train accuracy: 87.50% | Test loss: 0.5752 | Test accuracy: 70.00%\n",
      "Epoch: 8440 | Train loss: 0.3573 | Train accuracy: 87.50% | Test loss: 0.5750 | Test accuracy: 70.00%\n",
      "Epoch: 8450 | Train loss: 0.3566 | Train accuracy: 87.50% | Test loss: 0.5748 | Test accuracy: 70.00%\n",
      "Epoch: 8460 | Train loss: 0.3559 | Train accuracy: 87.50% | Test loss: 0.5746 | Test accuracy: 70.00%\n",
      "Epoch: 8470 | Train loss: 0.3552 | Train accuracy: 88.64% | Test loss: 0.5744 | Test accuracy: 70.00%\n",
      "Epoch: 8480 | Train loss: 0.3545 | Train accuracy: 88.64% | Test loss: 0.5741 | Test accuracy: 70.00%\n",
      "Epoch: 8490 | Train loss: 0.3538 | Train accuracy: 88.64% | Test loss: 0.5739 | Test accuracy: 70.00%\n",
      "Epoch: 8500 | Train loss: 0.3531 | Train accuracy: 88.64% | Test loss: 0.5737 | Test accuracy: 70.00%\n",
      "Epoch: 8510 | Train loss: 0.3524 | Train accuracy: 88.64% | Test loss: 0.5735 | Test accuracy: 70.00%\n",
      "Epoch: 8520 | Train loss: 0.3518 | Train accuracy: 88.64% | Test loss: 0.5733 | Test accuracy: 70.00%\n",
      "Epoch: 8530 | Train loss: 0.3511 | Train accuracy: 88.64% | Test loss: 0.5731 | Test accuracy: 70.00%\n",
      "Epoch: 8540 | Train loss: 0.3504 | Train accuracy: 88.64% | Test loss: 0.5729 | Test accuracy: 70.00%\n",
      "Epoch: 8550 | Train loss: 0.3497 | Train accuracy: 88.64% | Test loss: 0.5726 | Test accuracy: 70.00%\n",
      "Epoch: 8560 | Train loss: 0.3491 | Train accuracy: 88.64% | Test loss: 0.5724 | Test accuracy: 70.00%\n",
      "Epoch: 8570 | Train loss: 0.3484 | Train accuracy: 88.64% | Test loss: 0.5722 | Test accuracy: 70.00%\n",
      "Epoch: 8580 | Train loss: 0.3477 | Train accuracy: 88.64% | Test loss: 0.5720 | Test accuracy: 70.00%\n",
      "Epoch: 8590 | Train loss: 0.3471 | Train accuracy: 88.64% | Test loss: 0.5718 | Test accuracy: 70.00%\n",
      "Epoch: 8600 | Train loss: 0.3464 | Train accuracy: 88.64% | Test loss: 0.5716 | Test accuracy: 70.00%\n",
      "Epoch: 8610 | Train loss: 0.3457 | Train accuracy: 88.64% | Test loss: 0.5714 | Test accuracy: 70.00%\n",
      "Epoch: 8620 | Train loss: 0.3451 | Train accuracy: 88.64% | Test loss: 0.5711 | Test accuracy: 70.00%\n",
      "Epoch: 8630 | Train loss: 0.3444 | Train accuracy: 88.64% | Test loss: 0.5709 | Test accuracy: 70.00%\n",
      "Epoch: 8640 | Train loss: 0.3438 | Train accuracy: 88.64% | Test loss: 0.5707 | Test accuracy: 70.00%\n",
      "Epoch: 8650 | Train loss: 0.3431 | Train accuracy: 88.64% | Test loss: 0.5705 | Test accuracy: 70.00%\n",
      "Epoch: 8660 | Train loss: 0.3424 | Train accuracy: 88.64% | Test loss: 0.5703 | Test accuracy: 70.00%\n",
      "Epoch: 8670 | Train loss: 0.3418 | Train accuracy: 88.64% | Test loss: 0.5700 | Test accuracy: 70.00%\n",
      "Epoch: 8680 | Train loss: 0.3411 | Train accuracy: 88.64% | Test loss: 0.5698 | Test accuracy: 70.00%\n",
      "Epoch: 8690 | Train loss: 0.3405 | Train accuracy: 88.64% | Test loss: 0.5696 | Test accuracy: 70.00%\n",
      "Epoch: 8700 | Train loss: 0.3398 | Train accuracy: 88.64% | Test loss: 0.5694 | Test accuracy: 70.00%\n",
      "Epoch: 8710 | Train loss: 0.3392 | Train accuracy: 88.64% | Test loss: 0.5692 | Test accuracy: 70.00%\n",
      "Epoch: 8720 | Train loss: 0.3386 | Train accuracy: 88.64% | Test loss: 0.5690 | Test accuracy: 70.00%\n",
      "Epoch: 8730 | Train loss: 0.3379 | Train accuracy: 88.64% | Test loss: 0.5688 | Test accuracy: 70.00%\n",
      "Epoch: 8740 | Train loss: 0.3373 | Train accuracy: 88.64% | Test loss: 0.5686 | Test accuracy: 70.00%\n",
      "Epoch: 8750 | Train loss: 0.3366 | Train accuracy: 88.64% | Test loss: 0.5684 | Test accuracy: 70.00%\n",
      "Epoch: 8760 | Train loss: 0.3360 | Train accuracy: 88.64% | Test loss: 0.5682 | Test accuracy: 70.00%\n",
      "Epoch: 8770 | Train loss: 0.3354 | Train accuracy: 88.64% | Test loss: 0.5680 | Test accuracy: 70.00%\n",
      "Epoch: 8780 | Train loss: 0.3347 | Train accuracy: 88.64% | Test loss: 0.5678 | Test accuracy: 70.00%\n",
      "Epoch: 8790 | Train loss: 0.3341 | Train accuracy: 88.64% | Test loss: 0.5676 | Test accuracy: 70.00%\n",
      "Epoch: 8800 | Train loss: 0.3335 | Train accuracy: 88.64% | Test loss: 0.5674 | Test accuracy: 70.00%\n",
      "Epoch: 8810 | Train loss: 0.3328 | Train accuracy: 88.64% | Test loss: 0.5672 | Test accuracy: 70.00%\n",
      "Epoch: 8820 | Train loss: 0.3322 | Train accuracy: 88.64% | Test loss: 0.5669 | Test accuracy: 70.00%\n",
      "Epoch: 8830 | Train loss: 0.3316 | Train accuracy: 88.64% | Test loss: 0.5667 | Test accuracy: 70.00%\n",
      "Epoch: 8840 | Train loss: 0.3310 | Train accuracy: 88.64% | Test loss: 0.5665 | Test accuracy: 70.00%\n",
      "Epoch: 8850 | Train loss: 0.3304 | Train accuracy: 88.64% | Test loss: 0.5663 | Test accuracy: 70.00%\n",
      "Epoch: 8860 | Train loss: 0.3297 | Train accuracy: 88.64% | Test loss: 0.5661 | Test accuracy: 70.00%\n",
      "Epoch: 8870 | Train loss: 0.3291 | Train accuracy: 88.64% | Test loss: 0.5659 | Test accuracy: 70.00%\n",
      "Epoch: 8880 | Train loss: 0.3285 | Train accuracy: 88.64% | Test loss: 0.5656 | Test accuracy: 70.00%\n",
      "Epoch: 8890 | Train loss: 0.3279 | Train accuracy: 88.64% | Test loss: 0.5654 | Test accuracy: 70.00%\n",
      "Epoch: 8900 | Train loss: 0.3273 | Train accuracy: 88.64% | Test loss: 0.5652 | Test accuracy: 70.00%\n",
      "Epoch: 8910 | Train loss: 0.3267 | Train accuracy: 88.64% | Test loss: 0.5649 | Test accuracy: 70.00%\n",
      "Epoch: 8920 | Train loss: 0.3261 | Train accuracy: 88.64% | Test loss: 0.5647 | Test accuracy: 70.00%\n",
      "Epoch: 8930 | Train loss: 0.3255 | Train accuracy: 88.64% | Test loss: 0.5645 | Test accuracy: 70.00%\n",
      "Epoch: 8940 | Train loss: 0.3248 | Train accuracy: 88.64% | Test loss: 0.5642 | Test accuracy: 70.00%\n",
      "Epoch: 8950 | Train loss: 0.3242 | Train accuracy: 88.64% | Test loss: 0.5640 | Test accuracy: 70.00%\n",
      "Epoch: 8960 | Train loss: 0.3236 | Train accuracy: 88.64% | Test loss: 0.5638 | Test accuracy: 70.00%\n",
      "Epoch: 8970 | Train loss: 0.3230 | Train accuracy: 88.64% | Test loss: 0.5636 | Test accuracy: 70.00%\n",
      "Epoch: 8980 | Train loss: 0.3224 | Train accuracy: 88.64% | Test loss: 0.5634 | Test accuracy: 70.00%\n",
      "Epoch: 8990 | Train loss: 0.3218 | Train accuracy: 88.64% | Test loss: 0.5631 | Test accuracy: 70.00%\n",
      "Epoch: 9000 | Train loss: 0.3213 | Train accuracy: 88.64% | Test loss: 0.5629 | Test accuracy: 70.00%\n",
      "Epoch: 9010 | Train loss: 0.3207 | Train accuracy: 88.64% | Test loss: 0.5627 | Test accuracy: 70.00%\n",
      "Epoch: 9020 | Train loss: 0.3201 | Train accuracy: 88.64% | Test loss: 0.5625 | Test accuracy: 70.00%\n",
      "Epoch: 9030 | Train loss: 0.3195 | Train accuracy: 88.64% | Test loss: 0.5622 | Test accuracy: 70.00%\n",
      "Epoch: 9040 | Train loss: 0.3189 | Train accuracy: 88.64% | Test loss: 0.5620 | Test accuracy: 70.00%\n",
      "Epoch: 9050 | Train loss: 0.3183 | Train accuracy: 88.64% | Test loss: 0.5617 | Test accuracy: 70.00%\n",
      "Epoch: 9060 | Train loss: 0.3177 | Train accuracy: 88.64% | Test loss: 0.5615 | Test accuracy: 70.00%\n",
      "Epoch: 9070 | Train loss: 0.3172 | Train accuracy: 88.64% | Test loss: 0.5612 | Test accuracy: 70.00%\n",
      "Epoch: 9080 | Train loss: 0.3166 | Train accuracy: 88.64% | Test loss: 0.5610 | Test accuracy: 70.00%\n",
      "Epoch: 9090 | Train loss: 0.3160 | Train accuracy: 88.64% | Test loss: 0.5607 | Test accuracy: 70.00%\n",
      "Epoch: 9100 | Train loss: 0.3154 | Train accuracy: 88.64% | Test loss: 0.5604 | Test accuracy: 70.00%\n",
      "Epoch: 9110 | Train loss: 0.3149 | Train accuracy: 88.64% | Test loss: 0.5602 | Test accuracy: 70.00%\n",
      "Epoch: 9120 | Train loss: 0.3143 | Train accuracy: 88.64% | Test loss: 0.5600 | Test accuracy: 70.00%\n",
      "Epoch: 9130 | Train loss: 0.3137 | Train accuracy: 88.64% | Test loss: 0.5598 | Test accuracy: 70.00%\n",
      "Epoch: 9140 | Train loss: 0.3131 | Train accuracy: 88.64% | Test loss: 0.5595 | Test accuracy: 70.00%\n",
      "Epoch: 9150 | Train loss: 0.3126 | Train accuracy: 88.64% | Test loss: 0.5593 | Test accuracy: 70.00%\n",
      "Epoch: 9160 | Train loss: 0.3120 | Train accuracy: 88.64% | Test loss: 0.5590 | Test accuracy: 70.00%\n",
      "Epoch: 9170 | Train loss: 0.3114 | Train accuracy: 88.64% | Test loss: 0.5588 | Test accuracy: 70.00%\n",
      "Epoch: 9180 | Train loss: 0.3109 | Train accuracy: 88.64% | Test loss: 0.5586 | Test accuracy: 70.00%\n",
      "Epoch: 9190 | Train loss: 0.3103 | Train accuracy: 88.64% | Test loss: 0.5584 | Test accuracy: 70.00%\n",
      "Epoch: 9200 | Train loss: 0.3097 | Train accuracy: 88.64% | Test loss: 0.5581 | Test accuracy: 70.00%\n",
      "Epoch: 9210 | Train loss: 0.3092 | Train accuracy: 88.64% | Test loss: 0.5579 | Test accuracy: 70.00%\n",
      "Epoch: 9220 | Train loss: 0.3086 | Train accuracy: 88.64% | Test loss: 0.5577 | Test accuracy: 70.00%\n",
      "Epoch: 9230 | Train loss: 0.3081 | Train accuracy: 88.64% | Test loss: 0.5575 | Test accuracy: 70.00%\n",
      "Epoch: 9240 | Train loss: 0.3075 | Train accuracy: 88.64% | Test loss: 0.5573 | Test accuracy: 70.00%\n",
      "Epoch: 9250 | Train loss: 0.3070 | Train accuracy: 88.64% | Test loss: 0.5570 | Test accuracy: 70.00%\n",
      "Epoch: 9260 | Train loss: 0.3064 | Train accuracy: 88.64% | Test loss: 0.5568 | Test accuracy: 70.00%\n",
      "Epoch: 9270 | Train loss: 0.3059 | Train accuracy: 88.64% | Test loss: 0.5565 | Test accuracy: 70.00%\n",
      "Epoch: 9280 | Train loss: 0.3053 | Train accuracy: 88.64% | Test loss: 0.5563 | Test accuracy: 70.00%\n",
      "Epoch: 9290 | Train loss: 0.3048 | Train accuracy: 88.64% | Test loss: 0.5560 | Test accuracy: 70.00%\n",
      "Epoch: 9300 | Train loss: 0.3042 | Train accuracy: 88.64% | Test loss: 0.5558 | Test accuracy: 70.00%\n",
      "Epoch: 9310 | Train loss: 0.3037 | Train accuracy: 88.64% | Test loss: 0.5556 | Test accuracy: 70.00%\n",
      "Epoch: 9320 | Train loss: 0.3031 | Train accuracy: 88.64% | Test loss: 0.5553 | Test accuracy: 70.00%\n",
      "Epoch: 9330 | Train loss: 0.3026 | Train accuracy: 88.64% | Test loss: 0.5551 | Test accuracy: 70.00%\n",
      "Epoch: 9340 | Train loss: 0.3021 | Train accuracy: 88.64% | Test loss: 0.5548 | Test accuracy: 70.00%\n",
      "Epoch: 9350 | Train loss: 0.3015 | Train accuracy: 88.64% | Test loss: 0.5546 | Test accuracy: 70.00%\n",
      "Epoch: 9360 | Train loss: 0.3010 | Train accuracy: 88.64% | Test loss: 0.5543 | Test accuracy: 70.00%\n",
      "Epoch: 9370 | Train loss: 0.3005 | Train accuracy: 88.64% | Test loss: 0.5542 | Test accuracy: 70.00%\n",
      "Epoch: 9380 | Train loss: 0.2999 | Train accuracy: 88.64% | Test loss: 0.5539 | Test accuracy: 70.00%\n",
      "Epoch: 9390 | Train loss: 0.2994 | Train accuracy: 88.64% | Test loss: 0.5537 | Test accuracy: 70.00%\n",
      "Epoch: 9400 | Train loss: 0.2989 | Train accuracy: 88.64% | Test loss: 0.5534 | Test accuracy: 70.00%\n",
      "Epoch: 9410 | Train loss: 0.2984 | Train accuracy: 88.64% | Test loss: 0.5532 | Test accuracy: 70.00%\n",
      "Epoch: 9420 | Train loss: 0.2979 | Train accuracy: 88.64% | Test loss: 0.5529 | Test accuracy: 70.00%\n",
      "Epoch: 9430 | Train loss: 0.2973 | Train accuracy: 88.64% | Test loss: 0.5527 | Test accuracy: 70.00%\n",
      "Epoch: 9440 | Train loss: 0.2968 | Train accuracy: 88.64% | Test loss: 0.5525 | Test accuracy: 70.00%\n",
      "Epoch: 9450 | Train loss: 0.2963 | Train accuracy: 88.64% | Test loss: 0.5522 | Test accuracy: 70.00%\n",
      "Epoch: 9460 | Train loss: 0.2958 | Train accuracy: 88.64% | Test loss: 0.5520 | Test accuracy: 70.00%\n",
      "Epoch: 9470 | Train loss: 0.2953 | Train accuracy: 88.64% | Test loss: 0.5517 | Test accuracy: 70.00%\n",
      "Epoch: 9480 | Train loss: 0.2948 | Train accuracy: 88.64% | Test loss: 0.5515 | Test accuracy: 70.00%\n",
      "Epoch: 9490 | Train loss: 0.2943 | Train accuracy: 88.64% | Test loss: 0.5512 | Test accuracy: 70.00%\n",
      "Epoch: 9500 | Train loss: 0.2938 | Train accuracy: 89.77% | Test loss: 0.5510 | Test accuracy: 70.00%\n",
      "Epoch: 9510 | Train loss: 0.2933 | Train accuracy: 89.77% | Test loss: 0.5508 | Test accuracy: 70.00%\n",
      "Epoch: 9520 | Train loss: 0.2928 | Train accuracy: 89.77% | Test loss: 0.5505 | Test accuracy: 70.00%\n",
      "Epoch: 9530 | Train loss: 0.2923 | Train accuracy: 89.77% | Test loss: 0.5503 | Test accuracy: 70.00%\n",
      "Epoch: 9540 | Train loss: 0.2918 | Train accuracy: 89.77% | Test loss: 0.5500 | Test accuracy: 70.00%\n",
      "Epoch: 9550 | Train loss: 0.2913 | Train accuracy: 89.77% | Test loss: 0.5498 | Test accuracy: 70.00%\n",
      "Epoch: 9560 | Train loss: 0.2908 | Train accuracy: 89.77% | Test loss: 0.5496 | Test accuracy: 70.00%\n",
      "Epoch: 9570 | Train loss: 0.2903 | Train accuracy: 89.77% | Test loss: 0.5493 | Test accuracy: 70.00%\n",
      "Epoch: 9580 | Train loss: 0.2898 | Train accuracy: 89.77% | Test loss: 0.5491 | Test accuracy: 70.00%\n",
      "Epoch: 9590 | Train loss: 0.2893 | Train accuracy: 89.77% | Test loss: 0.5489 | Test accuracy: 70.00%\n",
      "Epoch: 9600 | Train loss: 0.2888 | Train accuracy: 89.77% | Test loss: 0.5486 | Test accuracy: 70.00%\n",
      "Epoch: 9610 | Train loss: 0.2883 | Train accuracy: 89.77% | Test loss: 0.5484 | Test accuracy: 70.00%\n",
      "Epoch: 9620 | Train loss: 0.2879 | Train accuracy: 89.77% | Test loss: 0.5482 | Test accuracy: 70.00%\n",
      "Epoch: 9630 | Train loss: 0.2874 | Train accuracy: 89.77% | Test loss: 0.5480 | Test accuracy: 70.00%\n",
      "Epoch: 9640 | Train loss: 0.2869 | Train accuracy: 89.77% | Test loss: 0.5478 | Test accuracy: 70.00%\n",
      "Epoch: 9650 | Train loss: 0.2864 | Train accuracy: 89.77% | Test loss: 0.5476 | Test accuracy: 70.00%\n",
      "Epoch: 9660 | Train loss: 0.2859 | Train accuracy: 89.77% | Test loss: 0.5473 | Test accuracy: 70.00%\n",
      "Epoch: 9670 | Train loss: 0.2855 | Train accuracy: 89.77% | Test loss: 0.5471 | Test accuracy: 70.00%\n",
      "Epoch: 9680 | Train loss: 0.2850 | Train accuracy: 89.77% | Test loss: 0.5469 | Test accuracy: 70.00%\n",
      "Epoch: 9690 | Train loss: 0.2845 | Train accuracy: 89.77% | Test loss: 0.5467 | Test accuracy: 70.00%\n",
      "Epoch: 9700 | Train loss: 0.2841 | Train accuracy: 89.77% | Test loss: 0.5465 | Test accuracy: 70.00%\n",
      "Epoch: 9710 | Train loss: 0.2836 | Train accuracy: 89.77% | Test loss: 0.5463 | Test accuracy: 70.00%\n",
      "Epoch: 9720 | Train loss: 0.2831 | Train accuracy: 89.77% | Test loss: 0.5461 | Test accuracy: 70.00%\n",
      "Epoch: 9730 | Train loss: 0.2827 | Train accuracy: 89.77% | Test loss: 0.5459 | Test accuracy: 70.00%\n",
      "Epoch: 9740 | Train loss: 0.2822 | Train accuracy: 89.77% | Test loss: 0.5458 | Test accuracy: 70.00%\n",
      "Epoch: 9750 | Train loss: 0.2817 | Train accuracy: 89.77% | Test loss: 0.5456 | Test accuracy: 70.00%\n",
      "Epoch: 9760 | Train loss: 0.2813 | Train accuracy: 90.91% | Test loss: 0.5454 | Test accuracy: 70.00%\n",
      "Epoch: 9770 | Train loss: 0.2808 | Train accuracy: 90.91% | Test loss: 0.5452 | Test accuracy: 70.00%\n",
      "Epoch: 9780 | Train loss: 0.2804 | Train accuracy: 90.91% | Test loss: 0.5450 | Test accuracy: 70.00%\n",
      "Epoch: 9790 | Train loss: 0.2799 | Train accuracy: 90.91% | Test loss: 0.5448 | Test accuracy: 70.00%\n",
      "Epoch: 9800 | Train loss: 0.2795 | Train accuracy: 90.91% | Test loss: 0.5446 | Test accuracy: 70.00%\n",
      "Epoch: 9810 | Train loss: 0.2790 | Train accuracy: 90.91% | Test loss: 0.5445 | Test accuracy: 70.00%\n",
      "Epoch: 9820 | Train loss: 0.2786 | Train accuracy: 90.91% | Test loss: 0.5443 | Test accuracy: 70.00%\n",
      "Epoch: 9830 | Train loss: 0.2781 | Train accuracy: 90.91% | Test loss: 0.5441 | Test accuracy: 70.00%\n",
      "Epoch: 9840 | Train loss: 0.2777 | Train accuracy: 90.91% | Test loss: 0.5439 | Test accuracy: 70.00%\n",
      "Epoch: 9850 | Train loss: 0.2772 | Train accuracy: 90.91% | Test loss: 0.5437 | Test accuracy: 70.00%\n",
      "Epoch: 9860 | Train loss: 0.2768 | Train accuracy: 90.91% | Test loss: 0.5436 | Test accuracy: 70.00%\n",
      "Epoch: 9870 | Train loss: 0.2764 | Train accuracy: 90.91% | Test loss: 0.5434 | Test accuracy: 70.00%\n",
      "Epoch: 9880 | Train loss: 0.2759 | Train accuracy: 90.91% | Test loss: 0.5433 | Test accuracy: 70.00%\n",
      "Epoch: 9890 | Train loss: 0.2755 | Train accuracy: 90.91% | Test loss: 0.5431 | Test accuracy: 70.00%\n",
      "Epoch: 9900 | Train loss: 0.2750 | Train accuracy: 90.91% | Test loss: 0.5429 | Test accuracy: 70.00%\n",
      "Epoch: 9910 | Train loss: 0.2746 | Train accuracy: 90.91% | Test loss: 0.5428 | Test accuracy: 70.00%\n",
      "Epoch: 9920 | Train loss: 0.2742 | Train accuracy: 90.91% | Test loss: 0.5426 | Test accuracy: 70.00%\n",
      "Epoch: 9930 | Train loss: 0.2737 | Train accuracy: 90.91% | Test loss: 0.5424 | Test accuracy: 70.00%\n",
      "Epoch: 9940 | Train loss: 0.2733 | Train accuracy: 90.91% | Test loss: 0.5423 | Test accuracy: 70.00%\n",
      "Epoch: 9950 | Train loss: 0.2729 | Train accuracy: 90.91% | Test loss: 0.5422 | Test accuracy: 70.00%\n",
      "Epoch: 9960 | Train loss: 0.2725 | Train accuracy: 90.91% | Test loss: 0.5420 | Test accuracy: 70.00%\n",
      "Epoch: 9970 | Train loss: 0.2720 | Train accuracy: 92.05% | Test loss: 0.5419 | Test accuracy: 70.00%\n",
      "Epoch: 9980 | Train loss: 0.2716 | Train accuracy: 92.05% | Test loss: 0.5417 | Test accuracy: 70.00%\n",
      "Epoch: 9990 | Train loss: 0.2712 | Train accuracy: 92.05% | Test loss: 0.5416 | Test accuracy: 70.00%\n",
      "Epoch: 10000 | Train loss: 0.2708 | Train accuracy: 92.05% | Test loss: 0.5414 | Test accuracy: 70.00%\n",
      "Epoch: 10010 | Train loss: 0.2704 | Train accuracy: 92.05% | Test loss: 0.5413 | Test accuracy: 70.00%\n",
      "Epoch: 10020 | Train loss: 0.2699 | Train accuracy: 92.05% | Test loss: 0.5411 | Test accuracy: 70.00%\n",
      "Epoch: 10030 | Train loss: 0.2695 | Train accuracy: 92.05% | Test loss: 0.5410 | Test accuracy: 70.00%\n",
      "Epoch: 10040 | Train loss: 0.2691 | Train accuracy: 92.05% | Test loss: 0.5409 | Test accuracy: 70.00%\n",
      "Epoch: 10050 | Train loss: 0.2687 | Train accuracy: 92.05% | Test loss: 0.5408 | Test accuracy: 70.00%\n",
      "Epoch: 10060 | Train loss: 0.2683 | Train accuracy: 92.05% | Test loss: 0.5406 | Test accuracy: 70.00%\n",
      "Epoch: 10070 | Train loss: 0.2679 | Train accuracy: 92.05% | Test loss: 0.5405 | Test accuracy: 70.00%\n",
      "Epoch: 10080 | Train loss: 0.2675 | Train accuracy: 92.05% | Test loss: 0.5403 | Test accuracy: 70.00%\n",
      "Epoch: 10090 | Train loss: 0.2671 | Train accuracy: 92.05% | Test loss: 0.5402 | Test accuracy: 70.00%\n",
      "Epoch: 10100 | Train loss: 0.2667 | Train accuracy: 92.05% | Test loss: 0.5400 | Test accuracy: 70.00%\n",
      "Epoch: 10110 | Train loss: 0.2662 | Train accuracy: 92.05% | Test loss: 0.5399 | Test accuracy: 70.00%\n",
      "Epoch: 10120 | Train loss: 0.2658 | Train accuracy: 92.05% | Test loss: 0.5398 | Test accuracy: 70.00%\n",
      "Epoch: 10130 | Train loss: 0.2654 | Train accuracy: 92.05% | Test loss: 0.5396 | Test accuracy: 70.00%\n",
      "Epoch: 10140 | Train loss: 0.2650 | Train accuracy: 92.05% | Test loss: 0.5396 | Test accuracy: 70.00%\n",
      "Epoch: 10150 | Train loss: 0.2646 | Train accuracy: 92.05% | Test loss: 0.5394 | Test accuracy: 70.00%\n",
      "Epoch: 10160 | Train loss: 0.2642 | Train accuracy: 92.05% | Test loss: 0.5393 | Test accuracy: 70.00%\n",
      "Epoch: 10170 | Train loss: 0.2639 | Train accuracy: 92.05% | Test loss: 0.5392 | Test accuracy: 70.00%\n",
      "Epoch: 10180 | Train loss: 0.2635 | Train accuracy: 92.05% | Test loss: 0.5391 | Test accuracy: 70.00%\n",
      "Epoch: 10190 | Train loss: 0.2631 | Train accuracy: 92.05% | Test loss: 0.5390 | Test accuracy: 70.00%\n",
      "Epoch: 10200 | Train loss: 0.2627 | Train accuracy: 92.05% | Test loss: 0.5389 | Test accuracy: 70.00%\n",
      "Epoch: 10210 | Train loss: 0.2623 | Train accuracy: 92.05% | Test loss: 0.5388 | Test accuracy: 70.00%\n",
      "Epoch: 10220 | Train loss: 0.2619 | Train accuracy: 92.05% | Test loss: 0.5387 | Test accuracy: 70.00%\n",
      "Epoch: 10230 | Train loss: 0.2615 | Train accuracy: 92.05% | Test loss: 0.5386 | Test accuracy: 70.00%\n",
      "Epoch: 10240 | Train loss: 0.2611 | Train accuracy: 92.05% | Test loss: 0.5385 | Test accuracy: 70.00%\n",
      "Epoch: 10250 | Train loss: 0.2607 | Train accuracy: 92.05% | Test loss: 0.5383 | Test accuracy: 70.00%\n",
      "Epoch: 10260 | Train loss: 0.2603 | Train accuracy: 92.05% | Test loss: 0.5383 | Test accuracy: 70.00%\n",
      "Epoch: 10270 | Train loss: 0.2600 | Train accuracy: 92.05% | Test loss: 0.5382 | Test accuracy: 70.00%\n",
      "Epoch: 10280 | Train loss: 0.2596 | Train accuracy: 92.05% | Test loss: 0.5381 | Test accuracy: 70.00%\n",
      "Epoch: 10290 | Train loss: 0.2592 | Train accuracy: 92.05% | Test loss: 0.5380 | Test accuracy: 70.00%\n",
      "Epoch: 10300 | Train loss: 0.2588 | Train accuracy: 92.05% | Test loss: 0.5379 | Test accuracy: 70.00%\n",
      "Epoch: 10310 | Train loss: 0.2584 | Train accuracy: 92.05% | Test loss: 0.5378 | Test accuracy: 70.00%\n",
      "Epoch: 10320 | Train loss: 0.2581 | Train accuracy: 92.05% | Test loss: 0.5378 | Test accuracy: 70.00%\n",
      "Epoch: 10330 | Train loss: 0.2577 | Train accuracy: 92.05% | Test loss: 0.5377 | Test accuracy: 70.00%\n",
      "Epoch: 10340 | Train loss: 0.2573 | Train accuracy: 92.05% | Test loss: 0.5377 | Test accuracy: 70.00%\n",
      "Epoch: 10350 | Train loss: 0.2569 | Train accuracy: 92.05% | Test loss: 0.5376 | Test accuracy: 70.00%\n",
      "Epoch: 10360 | Train loss: 0.2565 | Train accuracy: 92.05% | Test loss: 0.5375 | Test accuracy: 70.00%\n",
      "Epoch: 10370 | Train loss: 0.2561 | Train accuracy: 92.05% | Test loss: 0.5374 | Test accuracy: 70.00%\n",
      "Epoch: 10380 | Train loss: 0.2558 | Train accuracy: 92.05% | Test loss: 0.5374 | Test accuracy: 70.00%\n",
      "Epoch: 10390 | Train loss: 0.2554 | Train accuracy: 92.05% | Test loss: 0.5372 | Test accuracy: 70.00%\n",
      "Epoch: 10400 | Train loss: 0.2550 | Train accuracy: 92.05% | Test loss: 0.5371 | Test accuracy: 70.00%\n",
      "Epoch: 10410 | Train loss: 0.2547 | Train accuracy: 92.05% | Test loss: 0.5371 | Test accuracy: 70.00%\n",
      "Epoch: 10420 | Train loss: 0.2543 | Train accuracy: 92.05% | Test loss: 0.5370 | Test accuracy: 70.00%\n",
      "Epoch: 10430 | Train loss: 0.2539 | Train accuracy: 92.05% | Test loss: 0.5369 | Test accuracy: 70.00%\n",
      "Epoch: 10440 | Train loss: 0.2536 | Train accuracy: 92.05% | Test loss: 0.5369 | Test accuracy: 70.00%\n",
      "Epoch: 10450 | Train loss: 0.2532 | Train accuracy: 92.05% | Test loss: 0.5367 | Test accuracy: 70.00%\n",
      "Epoch: 10460 | Train loss: 0.2528 | Train accuracy: 92.05% | Test loss: 0.5367 | Test accuracy: 70.00%\n",
      "Epoch: 10470 | Train loss: 0.2525 | Train accuracy: 92.05% | Test loss: 0.5366 | Test accuracy: 70.00%\n",
      "Epoch: 10480 | Train loss: 0.2521 | Train accuracy: 92.05% | Test loss: 0.5365 | Test accuracy: 70.00%\n",
      "Epoch: 10490 | Train loss: 0.2518 | Train accuracy: 92.05% | Test loss: 0.5365 | Test accuracy: 70.00%\n",
      "Epoch: 10500 | Train loss: 0.2514 | Train accuracy: 92.05% | Test loss: 0.5364 | Test accuracy: 70.00%\n",
      "Epoch: 10510 | Train loss: 0.2510 | Train accuracy: 92.05% | Test loss: 0.5363 | Test accuracy: 70.00%\n",
      "Epoch: 10520 | Train loss: 0.2507 | Train accuracy: 92.05% | Test loss: 0.5362 | Test accuracy: 70.00%\n",
      "Epoch: 10530 | Train loss: 0.2503 | Train accuracy: 92.05% | Test loss: 0.5361 | Test accuracy: 70.00%\n",
      "Epoch: 10540 | Train loss: 0.2500 | Train accuracy: 92.05% | Test loss: 0.5360 | Test accuracy: 70.00%\n",
      "Epoch: 10550 | Train loss: 0.2496 | Train accuracy: 92.05% | Test loss: 0.5360 | Test accuracy: 70.00%\n",
      "Epoch: 10560 | Train loss: 0.2493 | Train accuracy: 92.05% | Test loss: 0.5359 | Test accuracy: 70.00%\n",
      "Epoch: 10570 | Train loss: 0.2489 | Train accuracy: 92.05% | Test loss: 0.5358 | Test accuracy: 70.00%\n",
      "Epoch: 10580 | Train loss: 0.2486 | Train accuracy: 92.05% | Test loss: 0.5358 | Test accuracy: 70.00%\n",
      "Epoch: 10590 | Train loss: 0.2482 | Train accuracy: 92.05% | Test loss: 0.5357 | Test accuracy: 70.00%\n",
      "Epoch: 10600 | Train loss: 0.2479 | Train accuracy: 92.05% | Test loss: 0.5356 | Test accuracy: 70.00%\n",
      "Epoch: 10610 | Train loss: 0.2475 | Train accuracy: 92.05% | Test loss: 0.5355 | Test accuracy: 70.00%\n",
      "Epoch: 10620 | Train loss: 0.2472 | Train accuracy: 92.05% | Test loss: 0.5355 | Test accuracy: 70.00%\n",
      "Epoch: 10630 | Train loss: 0.2469 | Train accuracy: 92.05% | Test loss: 0.5354 | Test accuracy: 70.00%\n",
      "Epoch: 10640 | Train loss: 0.2465 | Train accuracy: 92.05% | Test loss: 0.5354 | Test accuracy: 70.00%\n",
      "Epoch: 10650 | Train loss: 0.2462 | Train accuracy: 92.05% | Test loss: 0.5353 | Test accuracy: 70.00%\n",
      "Epoch: 10660 | Train loss: 0.2458 | Train accuracy: 92.05% | Test loss: 0.5352 | Test accuracy: 70.00%\n",
      "Epoch: 10670 | Train loss: 0.2455 | Train accuracy: 92.05% | Test loss: 0.5352 | Test accuracy: 70.00%\n",
      "Epoch: 10680 | Train loss: 0.2452 | Train accuracy: 92.05% | Test loss: 0.5351 | Test accuracy: 70.00%\n",
      "Epoch: 10690 | Train loss: 0.2448 | Train accuracy: 92.05% | Test loss: 0.5350 | Test accuracy: 70.00%\n",
      "Epoch: 10700 | Train loss: 0.2445 | Train accuracy: 92.05% | Test loss: 0.5350 | Test accuracy: 70.00%\n",
      "Epoch: 10710 | Train loss: 0.2442 | Train accuracy: 92.05% | Test loss: 0.5349 | Test accuracy: 70.00%\n",
      "Epoch: 10720 | Train loss: 0.2438 | Train accuracy: 92.05% | Test loss: 0.5349 | Test accuracy: 70.00%\n",
      "Epoch: 10730 | Train loss: 0.2435 | Train accuracy: 92.05% | Test loss: 0.5348 | Test accuracy: 70.00%\n",
      "Epoch: 10740 | Train loss: 0.2432 | Train accuracy: 92.05% | Test loss: 0.5348 | Test accuracy: 70.00%\n",
      "Epoch: 10750 | Train loss: 0.2429 | Train accuracy: 92.05% | Test loss: 0.5347 | Test accuracy: 70.00%\n",
      "Epoch: 10760 | Train loss: 0.2425 | Train accuracy: 92.05% | Test loss: 0.5346 | Test accuracy: 70.00%\n",
      "Epoch: 10770 | Train loss: 0.2422 | Train accuracy: 92.05% | Test loss: 0.5346 | Test accuracy: 70.00%\n",
      "Epoch: 10780 | Train loss: 0.2419 | Train accuracy: 92.05% | Test loss: 0.5345 | Test accuracy: 70.00%\n",
      "Epoch: 10790 | Train loss: 0.2416 | Train accuracy: 92.05% | Test loss: 0.5345 | Test accuracy: 70.00%\n",
      "Epoch: 10800 | Train loss: 0.2412 | Train accuracy: 93.18% | Test loss: 0.5345 | Test accuracy: 70.00%\n",
      "Epoch: 10810 | Train loss: 0.2409 | Train accuracy: 93.18% | Test loss: 0.5344 | Test accuracy: 70.00%\n",
      "Epoch: 10820 | Train loss: 0.2406 | Train accuracy: 93.18% | Test loss: 0.5343 | Test accuracy: 70.00%\n",
      "Epoch: 10830 | Train loss: 0.2403 | Train accuracy: 93.18% | Test loss: 0.5343 | Test accuracy: 70.00%\n",
      "Epoch: 10840 | Train loss: 0.2399 | Train accuracy: 93.18% | Test loss: 0.5343 | Test accuracy: 70.00%\n",
      "Epoch: 10850 | Train loss: 0.2396 | Train accuracy: 93.18% | Test loss: 0.5342 | Test accuracy: 70.00%\n",
      "Epoch: 10860 | Train loss: 0.2393 | Train accuracy: 93.18% | Test loss: 0.5342 | Test accuracy: 70.00%\n",
      "Epoch: 10870 | Train loss: 0.2390 | Train accuracy: 93.18% | Test loss: 0.5342 | Test accuracy: 70.00%\n",
      "Epoch: 10880 | Train loss: 0.2387 | Train accuracy: 93.18% | Test loss: 0.5341 | Test accuracy: 70.00%\n",
      "Epoch: 10890 | Train loss: 0.2384 | Train accuracy: 93.18% | Test loss: 0.5341 | Test accuracy: 70.00%\n",
      "Epoch: 10900 | Train loss: 0.2381 | Train accuracy: 93.18% | Test loss: 0.5341 | Test accuracy: 70.00%\n",
      "Epoch: 10910 | Train loss: 0.2377 | Train accuracy: 93.18% | Test loss: 0.5341 | Test accuracy: 70.00%\n",
      "Epoch: 10920 | Train loss: 0.2374 | Train accuracy: 93.18% | Test loss: 0.5341 | Test accuracy: 70.00%\n",
      "Epoch: 10930 | Train loss: 0.2371 | Train accuracy: 93.18% | Test loss: 0.5341 | Test accuracy: 70.00%\n",
      "Epoch: 10940 | Train loss: 0.2368 | Train accuracy: 93.18% | Test loss: 0.5340 | Test accuracy: 70.00%\n",
      "Epoch: 10950 | Train loss: 0.2365 | Train accuracy: 93.18% | Test loss: 0.5340 | Test accuracy: 70.00%\n",
      "Epoch: 10960 | Train loss: 0.2362 | Train accuracy: 93.18% | Test loss: 0.5340 | Test accuracy: 70.00%\n",
      "Epoch: 10970 | Train loss: 0.2359 | Train accuracy: 93.18% | Test loss: 0.5340 | Test accuracy: 70.00%\n",
      "Epoch: 10980 | Train loss: 0.2356 | Train accuracy: 93.18% | Test loss: 0.5340 | Test accuracy: 70.00%\n",
      "Epoch: 10990 | Train loss: 0.2353 | Train accuracy: 93.18% | Test loss: 0.5340 | Test accuracy: 70.00%\n",
      "Epoch: 11000 | Train loss: 0.2350 | Train accuracy: 93.18% | Test loss: 0.5339 | Test accuracy: 70.00%\n",
      "Epoch: 11010 | Train loss: 0.2347 | Train accuracy: 93.18% | Test loss: 0.5339 | Test accuracy: 70.00%\n",
      "Epoch: 11020 | Train loss: 0.2344 | Train accuracy: 93.18% | Test loss: 0.5339 | Test accuracy: 70.00%\n",
      "Epoch: 11030 | Train loss: 0.2341 | Train accuracy: 93.18% | Test loss: 0.5339 | Test accuracy: 70.00%\n",
      "Epoch: 11040 | Train loss: 0.2338 | Train accuracy: 93.18% | Test loss: 0.5339 | Test accuracy: 70.00%\n",
      "Epoch: 11050 | Train loss: 0.2335 | Train accuracy: 93.18% | Test loss: 0.5338 | Test accuracy: 70.00%\n",
      "Epoch: 11060 | Train loss: 0.2332 | Train accuracy: 93.18% | Test loss: 0.5338 | Test accuracy: 70.00%\n",
      "Epoch: 11070 | Train loss: 0.2329 | Train accuracy: 93.18% | Test loss: 0.5339 | Test accuracy: 70.00%\n",
      "Epoch: 11080 | Train loss: 0.2326 | Train accuracy: 93.18% | Test loss: 0.5338 | Test accuracy: 70.00%\n",
      "Epoch: 11090 | Train loss: 0.2323 | Train accuracy: 93.18% | Test loss: 0.5338 | Test accuracy: 70.00%\n",
      "Epoch: 11100 | Train loss: 0.2320 | Train accuracy: 93.18% | Test loss: 0.5338 | Test accuracy: 70.00%\n",
      "Epoch: 11110 | Train loss: 0.2317 | Train accuracy: 93.18% | Test loss: 0.5338 | Test accuracy: 70.00%\n",
      "Epoch: 11120 | Train loss: 0.2315 | Train accuracy: 93.18% | Test loss: 0.5338 | Test accuracy: 70.00%\n",
      "Epoch: 11130 | Train loss: 0.2312 | Train accuracy: 93.18% | Test loss: 0.5338 | Test accuracy: 70.00%\n",
      "Epoch: 11140 | Train loss: 0.2309 | Train accuracy: 93.18% | Test loss: 0.5337 | Test accuracy: 70.00%\n",
      "Epoch: 11150 | Train loss: 0.2306 | Train accuracy: 93.18% | Test loss: 0.5337 | Test accuracy: 70.00%\n",
      "Epoch: 11160 | Train loss: 0.2303 | Train accuracy: 93.18% | Test loss: 0.5337 | Test accuracy: 70.00%\n",
      "Epoch: 11170 | Train loss: 0.2300 | Train accuracy: 93.18% | Test loss: 0.5337 | Test accuracy: 70.00%\n",
      "Epoch: 11180 | Train loss: 0.2297 | Train accuracy: 93.18% | Test loss: 0.5338 | Test accuracy: 70.00%\n",
      "Epoch: 11190 | Train loss: 0.2294 | Train accuracy: 93.18% | Test loss: 0.5337 | Test accuracy: 70.00%\n",
      "Epoch: 11200 | Train loss: 0.2292 | Train accuracy: 93.18% | Test loss: 0.5337 | Test accuracy: 70.00%\n",
      "Epoch: 11210 | Train loss: 0.2289 | Train accuracy: 93.18% | Test loss: 0.5337 | Test accuracy: 70.00%\n",
      "Epoch: 11220 | Train loss: 0.2286 | Train accuracy: 93.18% | Test loss: 0.5338 | Test accuracy: 70.00%\n",
      "Epoch: 11230 | Train loss: 0.2283 | Train accuracy: 93.18% | Test loss: 0.5337 | Test accuracy: 70.00%\n",
      "Epoch: 11240 | Train loss: 0.2280 | Train accuracy: 93.18% | Test loss: 0.5337 | Test accuracy: 70.00%\n",
      "Epoch: 11250 | Train loss: 0.2278 | Train accuracy: 93.18% | Test loss: 0.5337 | Test accuracy: 70.00%\n",
      "Epoch: 11260 | Train loss: 0.2275 | Train accuracy: 93.18% | Test loss: 0.5338 | Test accuracy: 70.00%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "epochs = 15000\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# GIMME THE DATA\n",
    "X_train, Y_train = X_train.to(device=device), Y_train.to(device=device)\n",
    "X_test, Y_test = X_test.to(device=device), Y_test.to(device=device)\n",
    "\n",
    "previous_test_loss = 100\n",
    "for epoch in range(epochs):\n",
    "  model_0.train()\n",
    "\n",
    "  y_logits = model_0(X_train.to(device=device))\n",
    "  y_preds = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "  loss = loss_fn(y_logits, Y_train)\n",
    "  train_losses.append(loss)\n",
    "  accuracy = accuracy_fn(y_true=Y_train,\n",
    "                         y_preds=y_preds)\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  model_0.eval()\n",
    "  with torch.inference_mode():\n",
    "    test_logits = model_0(X_test)\n",
    "    test_preds = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "    test_loss = loss_fn(test_logits, Y_test)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracy = accuracy_fn(y_true=Y_test,\n",
    "                                y_preds=test_preds)\n",
    "    if test_loss > previous_test_loss and test_accuracy >= 80:\n",
    "      break\n",
    "    previous_test_loss = test_loss\n",
    "\n",
    "  if epoch % 10 == 0:\n",
    "    print(f\"Epoch: {epoch} | Train loss: {loss:.4f} | Train accuracy: {accuracy:.2f}% | Test loss: {test_loss:.4f} | Test accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "7e7f75ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x262931c3350>]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_losses = [x.detach().cpu().numpy() for x in test_losses]\n",
    "plt.plot(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0685e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_0.state_dict(), 'model_0_state_dict.pth')\n",
    "torch.save(model_0, 'model_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92398bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5998,  0.4919],\n",
       "        [-2.8339,  2.8714],\n",
       "        [ 2.1102, -2.4041],\n",
       "        [-1.7744,  1.6995],\n",
       "        [ 3.5863, -4.0410]], device='cuda:0')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get some raw outputs of our model (logits)\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits = model_0(X_test.to(device=device))\n",
    "\n",
    "y_logits[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f67671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5130e-01, 7.4870e-01],\n",
       "        [3.3173e-03, 9.9668e-01],\n",
       "        [9.8917e-01, 1.0832e-02],\n",
       "        [3.0064e-02, 9.6994e-01],\n",
       "        [9.9951e-01, 4.8675e-04],\n",
       "        [9.9931e-01, 6.8853e-04],\n",
       "        [5.7241e-01, 4.2759e-01],\n",
       "        [1.1680e-01, 8.8320e-01],\n",
       "        [4.7375e-02, 9.5263e-01],\n",
       "        [9.6932e-01, 3.0677e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_probs = torch.softmax(y_logits, dim=1)\n",
    "y_preds_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a11a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = set()\n",
    "for probs in y_preds_probs:\n",
    "  values.add(torch.argmax(probs).item())\n",
    "  print(torch.argmax(probs))\n",
    "values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
